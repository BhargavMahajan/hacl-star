/* 
  This file was generated by KreMLin <https://github.com/FStarLang/kremlin>
  KreMLin invocation: /home/nkulatov/new/kremlin/krml -add-include "TestLib.h" /dist/generic/testlib.c -skip-compilation -no-prefix Hacl.Impl.P256 -bundle Lib.* -bundle Spec.* -bundle Hacl.Impl.P256=Hacl.Impl.P256,Hacl.Spec.P256.*,Hacl.Spec.Curve25519.*,Hacl.Impl.Curve25519.* -library C,FStar -drop LowStar,Spec,Prims,Lib,C.Loops.*,Hacl.Spec.P256.Lemmas -add-include "c/Lib_PrintBuffer.h" -add-include "FStar_UInt_8_16_32_64.h" -tmpdir p256-c .output/prims.krml .output/FStar_Pervasives_Native.krml .output/FStar_Pervasives.krml .output/FStar_Reflection_Types.krml .output/FStar_Reflection_Data.krml .output/FStar_Order.krml .output/FStar_Reflection_Basic.krml .output/FStar_Mul.krml .output/FStar_Preorder.krml .output/FStar_Calc.krml .output/FStar_Squash.krml .output/FStar_Classical.krml .output/FStar_StrongExcludedMiddle.krml .output/FStar_FunctionalExtensionality.krml .output/FStar_List_Tot_Base.krml .output/FStar_List_Tot_Properties.krml .output/FStar_List_Tot.krml .output/FStar_Seq_Base.krml .output/FStar_Seq_Properties.krml .output/FStar_Seq.krml .output/FStar_Math_Lib.krml .output/FStar_Math_Lemmas.krml .output/FStar_BitVector.krml .output/FStar_UInt.krml .output/FStar_UInt32.krml .output/FStar_Int.krml .output/FStar_Int16.krml .output/FStar_Ghost.krml .output/FStar_ErasedLogic.krml .output/FStar_UInt64.krml .output/FStar_Set.krml .output/FStar_PropositionalExtensionality.krml .output/FStar_PredicateExtensionality.krml .output/FStar_TSet.krml .output/FStar_Monotonic_Heap.krml .output/FStar_Heap.krml .output/FStar_Map.krml .output/FStar_Monotonic_HyperHeap.krml .output/FStar_Monotonic_HyperStack.krml .output/FStar_HyperStack.krml .output/FStar_Monotonic_Witnessed.krml .output/FStar_HyperStack_ST.krml .output/FStar_HyperStack_All.krml .output/FStar_Exn.krml .output/FStar_ST.krml .output/FStar_All.krml .output/FStar_List.krml .output/FStar_Reflection_Const.krml .output/FStar_Char.krml .output/FStar_String.krml .output/FStar_Reflection_Derived.krml .output/FStar_Reflection_Derived_Lemmas.krml .output/FStar_Reflection.krml .output/FStar_Range.krml .output/FStar_Tactics_Types.krml .output/FStar_Tactics_Result.krml .output/FStar_Tactics_Effect.krml .output/FStar_Tactics_Util.krml .output/FStar_Tactics_Builtins.krml .output/FStar_Reflection_Formula.krml .output/FStar_Tactics_Derived.krml .output/FStar_Tactics_Logic.krml .output/FStar_Tactics.krml .output/FStar_Reflection_Arith.krml .output/FStar_Tactics_Canon.krml .output/FStar_Int64.krml .output/FStar_Int63.krml .output/FStar_Int32.krml .output/FStar_Int8.krml .output/FStar_UInt63.krml .output/FStar_UInt16.krml .output/FStar_UInt8.krml .output/FStar_Int_Cast.krml .output/FStar_UInt128.krml .output/FStar_Int_Cast_Full.krml .output/Lib_IntTypes.krml .output/Lib_RawIntTypes.krml .output/Lib_LoopCombinators.krml .output/Spec_Curve25519_Lemmas.krml .output/Lib_Sequence.krml .output/Lib_ByteSequence.krml .output/Spec_Curve25519.krml .output/Hacl_Spec_Curve25519_Field64_Definition.krml .output/FStar_Universe.krml .output/FStar_GSet.krml .output/FStar_ModifiesGen.krml .output/FStar_BigOps.krml .output/LowStar_Monotonic_Buffer.krml .output/LowStar_Buffer.krml .output/LowStar_BufferOps.krml .output/Spec_Loops.krml .output/C_Loops.krml .output/Lib_Loops.krml .output/LowStar_ImmutableBuffer.krml .output/Lib_Buffer.krml .output/Hacl_Spec_P256_Definitions.krml .output/Hacl_Impl_Curve25519_Lemmas.krml .output/Hacl_Spec_Curve25519_Field64_Lemmas.krml .output/Hacl_Spec_Curve25519_Field64_Core.krml .output/Hacl_Spec_P256_Lemmas.krml .output/Hacl_Spec_P256_Core.krml .output/Hacl_Spec_P256_SolinasReduction.krml .output/Hacl_Impl_Curve25519_Field64_Core.krml .output/Hacl_Spec_P256_MontgomeryMultiplication.krml .output/Hacl_Spec_P256_MontgomeryMultiplication_PointDouble.krml .output/Hacl_Spec_P256_MontgomeryMultiplication_PointAdd.krml .output/Hacl_Spec_P256_Ladder.krml .output/Hacl_Spec_P256_Normalisation.krml .output/Hacl_Impl_P256.krml
  F* version: f2134fe1
  KreMLin version: f534ac02
 */

#include "Hacl_Impl_P256.h"

typedef struct K___uint64_t_uint64_t_uint64_t_uint64_t_s
{
  uint64_t fst;
  uint64_t snd;
  uint64_t thd;
  uint64_t f3;
}
K___uint64_t_uint64_t_uint64_t_uint64_t;

typedef struct K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_s
{
  uint64_t fst;
  uint64_t snd;
  uint64_t thd;
  uint64_t f3;
  uint64_t f4;
  uint64_t f5;
  uint64_t f6;
  uint64_t f7;
}
K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t;

typedef struct K___uint64_t_uint64_t_s
{
  uint64_t fst;
  uint64_t snd;
}
K___uint64_t_uint64_t;

inline static K___uint64_t_uint64_t
Hacl_Spec_Curve25519_Field64_Core_addcarry(uint64_t x, uint64_t y, uint64_t cin)
{
  uint64_t res1 = x + cin;
  uint64_t c;
  if (res1 < cin)
    c = (uint64_t)1U;
  else
    c = (uint64_t)0U;
  uint64_t res = res1 + y;
  uint64_t c1;
  if (res < res1)
    c1 = c + (uint64_t)1U;
  else
    c1 = c;
  return ((K___uint64_t_uint64_t){ .fst = res, .snd = c1 });
}

inline static K___uint64_t_uint64_t
Hacl_Spec_Curve25519_Field64_Core_subborrow(uint64_t x, uint64_t y, uint64_t cin)
{
  uint64_t res = x - y - cin;
  uint64_t c;
  if (cin == (uint64_t)1U)
  {
    uint64_t ite;
    if (x <= y)
      ite = (uint64_t)1U;
    else
      ite = (uint64_t)0U;
    c = ite;
  }
  else
  {
    uint64_t ite;
    if (x < y)
      ite = (uint64_t)1U;
    else
      ite = (uint64_t)0U;
    c = ite;
  }
  return ((K___uint64_t_uint64_t){ .fst = res, .snd = c });
}

typedef struct K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_s
{
  uint64_t fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t snd;
}
K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t;

static K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_Curve25519_Field64_Core_mul1(K___uint64_t_uint64_t_uint64_t_uint64_t f, uint64_t u)
{
  uint64_t f0 = f.fst;
  uint64_t f1 = f.snd;
  uint64_t f2 = f.thd;
  uint64_t f3 = f.f3;
  FStar_UInt128_uint128 res0 = FStar_UInt128_mul_wide(f0, u);
  uint64_t l0 = FStar_UInt128_uint128_to_uint64(res0);
  uint64_t h0 = FStar_UInt128_uint128_to_uint64(FStar_UInt128_shift_right(res0, (uint32_t)64U));
  FStar_UInt128_uint128 res1 = FStar_UInt128_mul_wide(f1, u);
  uint64_t l1 = FStar_UInt128_uint128_to_uint64(res1);
  uint64_t h1 = FStar_UInt128_uint128_to_uint64(FStar_UInt128_shift_right(res1, (uint32_t)64U));
  FStar_UInt128_uint128 res2 = FStar_UInt128_mul_wide(f2, u);
  uint64_t l2 = FStar_UInt128_uint128_to_uint64(res2);
  uint64_t h2 = FStar_UInt128_uint128_to_uint64(FStar_UInt128_shift_right(res2, (uint32_t)64U));
  FStar_UInt128_uint128 res = FStar_UInt128_mul_wide(f3, u);
  uint64_t l3 = FStar_UInt128_uint128_to_uint64(res);
  uint64_t h3 = FStar_UInt128_uint128_to_uint64(FStar_UInt128_shift_right(res, (uint32_t)64U));
  uint64_t o0 = l0;
  K___uint64_t_uint64_t scrut = Hacl_Spec_Curve25519_Field64_Core_addcarry(l1, h0, (uint64_t)0U);
  uint64_t o1 = scrut.fst;
  uint64_t c0 = scrut.snd;
  K___uint64_t_uint64_t scrut0 = Hacl_Spec_Curve25519_Field64_Core_addcarry(l2, h1, c0);
  uint64_t o2 = scrut0.fst;
  uint64_t c1 = scrut0.snd;
  K___uint64_t_uint64_t scrut1 = Hacl_Spec_Curve25519_Field64_Core_addcarry(l3, h2, c1);
  uint64_t o3 = scrut1.fst;
  uint64_t c2 = scrut1.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t out = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 };
  uint64_t c3 = h3 + c2;
  return ((K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = c3, .snd = out });
}

static K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_Curve25519_Field64_Core_mul1_add(
  K___uint64_t_uint64_t_uint64_t_uint64_t f1,
  uint64_t u2,
  K___uint64_t_uint64_t_uint64_t_uint64_t f3
)
{
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 = Hacl_Spec_Curve25519_Field64_Core_mul1(f1, u2);
  uint64_t c = scrut0.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out0 = scrut0.snd;
  uint64_t o0 = out0.fst;
  uint64_t o1 = out0.snd;
  uint64_t o2 = out0.thd;
  uint64_t o3 = out0.f3;
  uint64_t f30 = f3.fst;
  uint64_t f31 = f3.snd;
  uint64_t f32 = f3.thd;
  uint64_t f33 = f3.f3;
  K___uint64_t_uint64_t
  scrut = Hacl_Spec_Curve25519_Field64_Core_addcarry(f30, o0, (uint64_t)0U);
  uint64_t o0_ = scrut.fst;
  uint64_t c0 = scrut.snd;
  K___uint64_t_uint64_t scrut1 = Hacl_Spec_Curve25519_Field64_Core_addcarry(f31, o1, c0);
  uint64_t o1_ = scrut1.fst;
  uint64_t c1 = scrut1.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_Curve25519_Field64_Core_addcarry(f32, o2, c1);
  uint64_t o2_ = scrut2.fst;
  uint64_t c2 = scrut2.snd;
  K___uint64_t_uint64_t scrut3 = Hacl_Spec_Curve25519_Field64_Core_addcarry(f33, o3, c2);
  uint64_t o3_ = scrut3.fst;
  uint64_t c3 = scrut3.snd;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  out = { .fst = o0_, .snd = o1_, .thd = o2_, .f3 = o3_ };
  uint64_t c4 = c + c3;
  return ((K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = c4, .snd = out });
}

typedef struct
K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_s
{
  K___uint64_t_uint64_t_uint64_t_uint64_t fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t snd;
}
K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t;

static K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_Curve25519_Field64_Core_add4(
  K___uint64_t_uint64_t_uint64_t_uint64_t uu____705,
  K___uint64_t_uint64_t_uint64_t_uint64_t uu____706
)
{
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut = { .fst = uu____705, .snd = uu____706 };
  uint64_t f23 = scrut.snd.f3;
  uint64_t f22 = scrut.snd.thd;
  uint64_t f21 = scrut.snd.snd;
  uint64_t f20 = scrut.snd.fst;
  uint64_t f13 = scrut.fst.f3;
  uint64_t f12 = scrut.fst.thd;
  uint64_t f11 = scrut.fst.snd;
  uint64_t f10 = scrut.fst.fst;
  K___uint64_t_uint64_t
  scrut0 = Hacl_Spec_Curve25519_Field64_Core_addcarry(f10, f20, (uint64_t)0U);
  uint64_t o0 = scrut0.fst;
  uint64_t c0 = scrut0.snd;
  K___uint64_t_uint64_t scrut1 = Hacl_Spec_Curve25519_Field64_Core_addcarry(f11, f21, c0);
  uint64_t o1 = scrut1.fst;
  uint64_t c1 = scrut1.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_Curve25519_Field64_Core_addcarry(f12, f22, c1);
  uint64_t o2 = scrut2.fst;
  uint64_t c2 = scrut2.snd;
  K___uint64_t_uint64_t scrut3 = Hacl_Spec_Curve25519_Field64_Core_addcarry(f13, f23, c2);
  uint64_t o3 = scrut3.fst;
  uint64_t c3 = scrut3.snd;
  return
    (
      (K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t){
        .fst = c3,
        .snd = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 }
      }
    );
}

static K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_Curve25519_Field64_Core_mul4(
  K___uint64_t_uint64_t_uint64_t_uint64_t f,
  K___uint64_t_uint64_t_uint64_t_uint64_t r
)
{
  uint64_t f0 = f.fst;
  uint64_t f1 = f.snd;
  uint64_t f2 = f.thd;
  uint64_t f3 = f.f3;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut = Hacl_Spec_Curve25519_Field64_Core_mul1(r, f0);
  uint64_t c0 = scrut.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out0 = scrut.snd;
  uint64_t o00 = out0.fst;
  uint64_t o01 = out0.snd;
  uint64_t o02 = out0.thd;
  uint64_t o03 = out0.f3;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 =
    Hacl_Spec_Curve25519_Field64_Core_mul1_add(r,
      f1,
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = o01, .snd = o02, .thd = o03, .f3 = c0 }));
  uint64_t c1 = scrut0.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out1 = scrut0.snd;
  uint64_t o11 = out1.fst;
  uint64_t o12 = out1.snd;
  uint64_t o13 = out1.thd;
  uint64_t o14 = out1.f3;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut1 =
    Hacl_Spec_Curve25519_Field64_Core_mul1_add(r,
      f2,
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = o12, .snd = o13, .thd = o14, .f3 = c1 }));
  uint64_t c2 = scrut1.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out2 = scrut1.snd;
  uint64_t o22 = out2.fst;
  uint64_t o23 = out2.snd;
  uint64_t o24 = out2.thd;
  uint64_t o25 = out2.f3;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut2 =
    Hacl_Spec_Curve25519_Field64_Core_mul1_add(r,
      f3,
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = o23, .snd = o24, .thd = o25, .f3 = c2 }));
  uint64_t c3 = scrut2.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t out3 = scrut2.snd;
  uint64_t o33 = out3.fst;
  uint64_t o34 = out3.snd;
  uint64_t o35 = out3.thd;
  uint64_t o36 = out3.f3;
  uint64_t o37 = c3;
  return
    (
      (K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t){
        .fst = o00,
        .snd = o11,
        .thd = o22,
        .f3 = o33,
        .f4 = o34,
        .f5 = o35,
        .f6 = o36,
        .f7 = o37
      }
    );
}

static uint64_t Hacl_Spec_P256_Core_store_high_low_u(uint32_t high, uint32_t low)
{
  uint64_t as_uint64_high = (uint64_t)high;
  uint64_t as_uint64_high1 = as_uint64_high << (uint32_t)32U;
  uint64_t as_uint64_low = (uint64_t)low;
  return as_uint64_low ^ as_uint64_high1;
}

static K___uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(
  uint64_t carry,
  K___uint64_t_uint64_t_uint64_t_uint64_t a
)
{
  K___uint64_t_uint64_t_uint64_t_uint64_t
  p256 =
    {
      .fst = (uint64_t)0xffffffffffffffffU,
      .snd = (uint64_t)0xffffffffU,
      .thd = (uint64_t)0U,
      .f3 = (uint64_t)0xffffffff00000001U
    };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 = { .fst = a, .snd = p256 };
  uint64_t f23 = scrut0.snd.f3;
  uint64_t f22 = scrut0.snd.thd;
  uint64_t f21 = scrut0.snd.snd;
  uint64_t f20 = scrut0.snd.fst;
  uint64_t f13 = scrut0.fst.f3;
  uint64_t f12 = scrut0.fst.thd;
  uint64_t f11 = scrut0.fst.snd;
  uint64_t f10 = scrut0.fst.fst;
  K___uint64_t_uint64_t
  scrut1 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f10, f20, (uint64_t)0U);
  uint64_t o0 = scrut1.fst;
  uint64_t c0 = scrut1.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f11, f21, c0);
  uint64_t o1 = scrut2.fst;
  uint64_t c1 = scrut2.snd;
  K___uint64_t_uint64_t scrut3 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f12, f22, c1);
  uint64_t o2 = scrut3.fst;
  uint64_t c2 = scrut3.snd;
  K___uint64_t_uint64_t scrut4 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f13, f23, c2);
  uint64_t o3 = scrut4.fst;
  uint64_t c3 = scrut4.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut5 = { .fst = c3, .snd = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 } };
  uint64_t x16 = scrut5.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r = scrut5.snd;
  K___uint64_t_uint64_t
  scrut6 = Hacl_Spec_Curve25519_Field64_Core_subborrow(carry, (uint64_t)0U, x16);
  uint64_t c = scrut6.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut = { .fst = r, .snd = a };
  uint64_t y3 = scrut.snd.f3;
  uint64_t y2 = scrut.snd.thd;
  uint64_t y1 = scrut.snd.snd;
  uint64_t y0 = scrut.snd.fst;
  uint64_t x3 = scrut.fst.f3;
  uint64_t x2 = scrut.fst.thd;
  uint64_t x1 = scrut.fst.snd;
  uint64_t x0 = scrut.fst.fst;
  uint64_t b0 = (uint64_t)0U;
  uint64_t x210;
  if (c == b0)
    x210 = (uint64_t)0U;
  else
    x210 = (uint64_t)18446744073709551615U;
  uint64_t r00 = y0 & x210 | x0 & ~x210;
  uint64_t b1 = (uint64_t)0U;
  uint64_t x211;
  if (c == b1)
    x211 = (uint64_t)0U;
  else
    x211 = (uint64_t)18446744073709551615U;
  uint64_t r10 = y1 & x211 | x1 & ~x211;
  uint64_t b2 = (uint64_t)0U;
  uint64_t x212;
  if (c == b2)
    x212 = (uint64_t)0U;
  else
    x212 = (uint64_t)18446744073709551615U;
  uint64_t r20 = y2 & x212 | x2 & ~x212;
  uint64_t b = (uint64_t)0U;
  uint64_t x21;
  if (c == b)
    x21 = (uint64_t)0U;
  else
    x21 = (uint64_t)18446744073709551615U;
  uint64_t r30 = y3 & x21 | x3 & ~x21;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut7 = { .fst = r00, .snd = r10, .thd = r20, .f3 = r30 };
  uint64_t r0 = scrut7.fst;
  uint64_t r1 = scrut7.snd;
  uint64_t r2 = scrut7.thd;
  uint64_t r3 = scrut7.f3;
  return
    ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = r0, .snd = r1, .thd = r2, .f3 = r3 });
}

typedef struct
K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_s
{
  uint64_t fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t snd;
}
K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t;

typedef struct
K___K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_s
{
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t snd;
}
K___K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t;

static K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_P256_Core_add8_without_carry(
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t a,
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t b
)
{
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 = { .fst = a, .snd = b };
  uint64_t b7 = scrut0.snd.f7;
  uint64_t b6 = scrut0.snd.f6;
  uint64_t b5 = scrut0.snd.f5;
  uint64_t b4 = scrut0.snd.f4;
  uint64_t b3 = scrut0.snd.f3;
  uint64_t b2 = scrut0.snd.thd;
  uint64_t b1 = scrut0.snd.snd;
  uint64_t b0 = scrut0.snd.fst;
  uint64_t a7 = scrut0.fst.f7;
  uint64_t a6 = scrut0.fst.f6;
  uint64_t a5 = scrut0.fst.f5;
  uint64_t a4 = scrut0.fst.f4;
  uint64_t a3 = scrut0.fst.f3;
  uint64_t a2 = scrut0.fst.thd;
  uint64_t a1 = scrut0.fst.snd;
  uint64_t a0 = scrut0.fst.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut1 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a0, .snd = a1, .thd = a2, .f3 = a3 }
      ),
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = b0, .snd = b1, .thd = b2, .f3 = b3 }));
  uint64_t c3 = scrut1.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r = scrut1.snd;
  K___uint64_t_uint64_t scrut = Hacl_Spec_Curve25519_Field64_Core_addcarry(c3, a4, b4);
  uint64_t o4 = scrut.fst;
  uint64_t c4 = scrut.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_Curve25519_Field64_Core_addcarry(c4, a5, b5);
  uint64_t o5 = scrut2.fst;
  uint64_t c5 = scrut2.snd;
  K___uint64_t_uint64_t scrut3 = Hacl_Spec_Curve25519_Field64_Core_addcarry(c5, a6, b6);
  uint64_t o6 = scrut3.fst;
  uint64_t c6 = scrut3.snd;
  K___uint64_t_uint64_t scrut4 = Hacl_Spec_Curve25519_Field64_Core_addcarry(c6, a7, b7);
  uint64_t o7 = scrut4.fst;
  uint64_t c7 = scrut4.snd;
  uint64_t o0 = r.fst;
  uint64_t o1 = r.snd;
  uint64_t o2 = r.thd;
  uint64_t o3 = r.f3;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  out = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3, .f4 = o4, .f5 = o5, .f6 = o6, .f7 = o7 };
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut5 = { .fst = c7, .snd = out };
  return scrut5.snd;
}

typedef struct
K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_s
{
  uint64_t fst;
  uint64_t snd;
  uint64_t thd;
  uint64_t f3;
  uint64_t f4;
  uint64_t f5;
  uint64_t f6;
  uint64_t f7;
  uint64_t f8;
}
K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t;

static K___uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_P256_Core_montgomery_multiplication(
  K___uint64_t_uint64_t_uint64_t_uint64_t uu____3297,
  K___uint64_t_uint64_t_uint64_t_uint64_t uu____3298
)
{
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 = { .fst = uu____3297, .snd = uu____3298 };
  uint64_t b3 = scrut0.snd.f3;
  uint64_t b2 = scrut0.snd.thd;
  uint64_t b1 = scrut0.snd.snd;
  uint64_t b0 = scrut0.snd.fst;
  uint64_t a3 = scrut0.fst.f3;
  uint64_t a2 = scrut0.fst.thd;
  uint64_t a1 = scrut0.fst.snd;
  uint64_t a0 = scrut0.fst.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  primeU =
    {
      .fst = (uint64_t)0xffffffffffffffffU,
      .snd = (uint64_t)0x00000000ffffffffU,
      .thd = (uint64_t)0U,
      .f3 = (uint64_t)0xffffffff00000001U
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut1 =
    Hacl_Spec_Curve25519_Field64_Core_mul4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a0, .snd = a1, .thd = a2, .f3 = a3 }
      ),
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = b0, .snd = b1, .thd = b2, .f3 = b3 }));
  uint64_t t_0 = scrut1.fst;
  uint64_t t_1 = scrut1.snd;
  uint64_t t_2 = scrut1.thd;
  uint64_t t_3 = scrut1.f3;
  uint64_t t_4 = scrut1.f4;
  uint64_t t_5 = scrut1.f5;
  uint64_t t_6 = scrut1.f6;
  uint64_t t_7 = scrut1.f7;
  uint64_t t1 = t_0;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut2 = Hacl_Spec_Curve25519_Field64_Core_mul1(primeU, t1);
  uint64_t c0 = scrut2.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t f4 = scrut2.snd;
  uint64_t f00 = f4.fst;
  uint64_t f10 = f4.snd;
  uint64_t f20 = f4.thd;
  uint64_t f30 = f4.f3;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t2 =
    {
      .fst = f00, .snd = f10, .thd = f20, .f3 = f30, .f4 = c0, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  scrut3 =
    {
      .fst = {
        .fst = t_0, .snd = t_1, .thd = t_2, .f3 = t_3, .f4 = t_4, .f5 = t_5, .f6 = t_6, .f7 = t_7
      },
      .snd = t2
    };
  uint64_t b7 = scrut3.snd.f7;
  uint64_t b6 = scrut3.snd.f6;
  uint64_t b5 = scrut3.snd.f5;
  uint64_t b4 = scrut3.snd.f4;
  uint64_t b31 = scrut3.snd.f3;
  uint64_t b21 = scrut3.snd.thd;
  uint64_t b11 = scrut3.snd.snd;
  uint64_t b01 = scrut3.snd.fst;
  uint64_t a70 = scrut3.fst.f7;
  uint64_t a60 = scrut3.fst.f6;
  uint64_t a50 = scrut3.fst.f5;
  uint64_t a40 = scrut3.fst.f4;
  uint64_t a310 = scrut3.fst.f3;
  uint64_t a210 = scrut3.fst.thd;
  uint64_t a110 = scrut3.fst.snd;
  uint64_t a01 = scrut3.fst.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut4 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a01,
          .snd = a110,
          .thd = a210,
          .f3 = a310
        }
      ),
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = b01, .snd = b11, .thd = b21, .f3 = b31 }));
  uint64_t c3 = scrut4.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r = scrut4.snd;
  K___uint64_t_uint64_t scrut = Hacl_Spec_Curve25519_Field64_Core_addcarry(c3, a40, b4);
  uint64_t o4 = scrut.fst;
  uint64_t c4 = scrut.snd;
  K___uint64_t_uint64_t scrut5 = Hacl_Spec_Curve25519_Field64_Core_addcarry(c4, a50, b5);
  uint64_t o5 = scrut5.fst;
  uint64_t c5 = scrut5.snd;
  K___uint64_t_uint64_t scrut6 = Hacl_Spec_Curve25519_Field64_Core_addcarry(c5, a60, b6);
  uint64_t o6 = scrut6.fst;
  uint64_t c6 = scrut6.snd;
  K___uint64_t_uint64_t scrut7 = Hacl_Spec_Curve25519_Field64_Core_addcarry(c6, a70, b7);
  uint64_t o7 = scrut7.fst;
  uint64_t c7 = scrut7.snd;
  uint64_t o0 = r.fst;
  uint64_t o1 = r.snd;
  uint64_t o2 = r.thd;
  uint64_t o3 = r.f3;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t3 =
    { .fst = o0, .snd = o1, .thd = o2, .f3 = o3, .f4 = o4, .f5 = o5, .f6 = o6, .f7 = o7, .f8 = c7 };
  uint64_t a111 = t3.snd;
  uint64_t a211 = t3.thd;
  uint64_t a311 = t3.f3;
  uint64_t a41 = t3.f4;
  uint64_t a51 = t3.f5;
  uint64_t a61 = t3.f6;
  uint64_t a71 = t3.f7;
  uint64_t a8 = t3.f8;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t_state0 =
    { .fst = a111, .snd = a211, .thd = a311, .f3 = a41, .f4 = a51, .f5 = a61, .f6 = a71, .f7 = a8 };
  K___uint64_t_uint64_t_uint64_t_uint64_t
  primeU10 =
    {
      .fst = (uint64_t)0xffffffffffffffffU,
      .snd = (uint64_t)0x00000000ffffffffU,
      .thd = (uint64_t)0U,
      .f3 = (uint64_t)0xffffffff00000001U
    };
  uint64_t t110 = t_state0.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut8 = Hacl_Spec_Curve25519_Field64_Core_mul1(primeU10, t110);
  uint64_t c1 = scrut8.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t f5 = scrut8.snd;
  uint64_t f01 = f5.fst;
  uint64_t f11 = f5.snd;
  uint64_t f21 = f5.thd;
  uint64_t f31 = f5.f3;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t210 =
    {
      .fst = f01, .snd = f11, .thd = f21, .f3 = f31, .f4 = c1, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t310 = Hacl_Spec_P256_Core_add8_without_carry(t_state0, t210);
  uint64_t a112 = t310.snd;
  uint64_t a212 = t310.thd;
  uint64_t a312 = t310.f3;
  uint64_t a42 = t310.f4;
  uint64_t a52 = t310.f5;
  uint64_t a62 = t310.f6;
  uint64_t a72 = t310.f7;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t_state1 =
    {
      .fst = a112, .snd = a212, .thd = a312, .f3 = a42, .f4 = a52, .f5 = a62, .f6 = a72,
      .f7 = (uint64_t)0U
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t
  primeU11 =
    {
      .fst = (uint64_t)0xffffffffffffffffU,
      .snd = (uint64_t)0x00000000ffffffffU,
      .thd = (uint64_t)0U,
      .f3 = (uint64_t)0xffffffff00000001U
    };
  uint64_t t111 = t_state1.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut9 = Hacl_Spec_Curve25519_Field64_Core_mul1(primeU11, t111);
  uint64_t c2 = scrut9.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t f6 = scrut9.snd;
  uint64_t f02 = f6.fst;
  uint64_t f12 = f6.snd;
  uint64_t f22 = f6.thd;
  uint64_t f32 = f6.f3;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t211 =
    {
      .fst = f02, .snd = f12, .thd = f22, .f3 = f32, .f4 = c2, .f5 = (uint64_t)0U,
      .f6 = (uint64_t)0U, .f7 = (uint64_t)0U
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t311 = Hacl_Spec_P256_Core_add8_without_carry(t_state1, t211);
  uint64_t a113 = t311.snd;
  uint64_t a213 = t311.thd;
  uint64_t a313 = t311.f3;
  uint64_t a43 = t311.f4;
  uint64_t a53 = t311.f5;
  uint64_t a63 = t311.f6;
  uint64_t a73 = t311.f7;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t_state2 =
    {
      .fst = a113, .snd = a213, .thd = a313, .f3 = a43, .f4 = a53, .f5 = a63, .f6 = a73,
      .f7 = (uint64_t)0U
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t
  primeU1 =
    {
      .fst = (uint64_t)0xffffffffffffffffU,
      .snd = (uint64_t)0x00000000ffffffffU,
      .thd = (uint64_t)0U,
      .f3 = (uint64_t)0xffffffff00000001U
    };
  uint64_t t112 = t_state2.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut10 = Hacl_Spec_Curve25519_Field64_Core_mul1(primeU1, t112);
  uint64_t c = scrut10.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t f = scrut10.snd;
  uint64_t f0 = f.fst;
  uint64_t f1 = f.snd;
  uint64_t f2 = f.thd;
  uint64_t f3 = f.f3;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t212 =
    {
      .fst = f0, .snd = f1, .thd = f2, .f3 = f3, .f4 = c, .f5 = (uint64_t)0U, .f6 = (uint64_t)0U,
      .f7 = (uint64_t)0U
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t312 = Hacl_Spec_P256_Core_add8_without_carry(t_state2, t212);
  uint64_t a11 = t312.snd;
  uint64_t a21 = t312.thd;
  uint64_t a31 = t312.f3;
  uint64_t a4 = t312.f4;
  uint64_t a5 = t312.f5;
  uint64_t a6 = t312.f6;
  uint64_t a7 = t312.f7;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  t_state3 =
    {
      .fst = a11, .snd = a21, .thd = a31, .f3 = a4, .f4 = a5, .f5 = a6, .f6 = a7, .f7 = (uint64_t)0U
    };
  uint64_t t0 = t_state3.fst;
  uint64_t t11 = t_state3.snd;
  uint64_t t21 = t_state3.thd;
  uint64_t t31 = t_state3.f3;
  uint64_t t4 = t_state3.f4;
  return
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(t4,
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = t0, .snd = t11, .thd = t21, .f3 = t31 }));
}

typedef struct K___uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_s
{
  uint32_t fst;
  uint32_t snd;
  uint32_t thd;
  uint32_t f3;
  uint32_t f4;
  uint32_t f5;
  uint32_t f6;
  uint32_t f7;
}
K___uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t;

static K___uint64_t_uint64_t_uint64_t_uint64_t
Hacl_Spec_P256_SolinasReduction_solinas_reduction(
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t uu____2294
)
{
  uint64_t f0 = uu____2294.fst;
  uint64_t f1 = uu____2294.snd;
  uint64_t f2 = uu____2294.thd;
  uint64_t f3 = uu____2294.f3;
  uint64_t f4 = uu____2294.f4;
  uint64_t f5 = uu____2294.f5;
  uint64_t f6 = uu____2294.f6;
  uint64_t f7 = uu____2294.f7;
  uint32_t c0 = (uint32_t)f0;
  uint32_t c1 = (uint32_t)(f0 >> (uint32_t)32U);
  uint32_t c2 = (uint32_t)f1;
  uint32_t c3 = (uint32_t)(f1 >> (uint32_t)32U);
  uint32_t c4 = (uint32_t)f2;
  uint32_t c5 = (uint32_t)(f2 >> (uint32_t)32U);
  uint32_t c6 = (uint32_t)f3;
  uint32_t c7 = (uint32_t)(f3 >> (uint32_t)32U);
  uint32_t c8 = (uint32_t)f4;
  uint32_t c9 = (uint32_t)(f4 >> (uint32_t)32U);
  uint32_t c10 = (uint32_t)f5;
  uint32_t c11 = (uint32_t)(f5 >> (uint32_t)32U);
  uint32_t c12 = (uint32_t)f6;
  uint32_t c13 = (uint32_t)(f6 >> (uint32_t)32U);
  uint32_t c14 = (uint32_t)f7;
  uint32_t c15 = (uint32_t)(f7 >> (uint32_t)32U);
  K___uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t
  c_low = { .fst = c0, .snd = c1, .thd = c2, .f3 = c3, .f4 = c4, .f5 = c5, .f6 = c6, .f7 = c7 };
  K___uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t_uint32_t
  c_high =
    { .fst = c8, .snd = c9, .thd = c10, .f3 = c11, .f4 = c12, .f5 = c13, .f6 = c14, .f7 = c15 };
  uint32_t c010 = c_low.fst;
  uint32_t c160 = c_low.snd;
  uint32_t c210 = c_low.thd;
  uint32_t c310 = c_low.f3;
  uint32_t c41 = c_low.f4;
  uint32_t c51 = c_low.f5;
  uint32_t c61 = c_low.f6;
  uint32_t c71 = c_low.f7;
  uint64_t b00 = Hacl_Spec_P256_Core_store_high_low_u(c160, c010);
  uint64_t b10 = Hacl_Spec_P256_Core_store_high_low_u(c310, c210);
  uint64_t b20 = Hacl_Spec_P256_Core_store_high_low_u(c51, c41);
  uint64_t b30 = Hacl_Spec_P256_Core_store_high_low_u(c71, c61);
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state0 = { .fst = b00, .snd = b10, .thd = b20, .f3 = b30 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 =
    {
      .fst = state0,
      .snd = {
        .fst = (uint64_t)0xffffffffffffffffU,
        .snd = (uint64_t)0xffffffffU,
        .thd = (uint64_t)0U,
        .f3 = (uint64_t)0xffffffff00000001U
      }
    };
  uint64_t f230 = scrut0.snd.f3;
  uint64_t f220 = scrut0.snd.thd;
  uint64_t f210 = scrut0.snd.snd;
  uint64_t f200 = scrut0.snd.fst;
  uint64_t f130 = scrut0.fst.f3;
  uint64_t f120 = scrut0.fst.thd;
  uint64_t f110 = scrut0.fst.snd;
  uint64_t f100 = scrut0.fst.fst;
  K___uint64_t_uint64_t
  scrut1 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f100, f200, (uint64_t)0U);
  uint64_t o00 = scrut1.fst;
  uint64_t c011 = scrut1.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f110, f210, c011);
  uint64_t o10 = scrut2.fst;
  uint64_t c161 = scrut2.snd;
  K___uint64_t_uint64_t scrut3 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f120, f220, c161);
  uint64_t o20 = scrut3.fst;
  uint64_t c211 = scrut3.snd;
  K___uint64_t_uint64_t scrut4 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f130, f230, c211);
  uint64_t o30 = scrut4.fst;
  uint64_t c311 = scrut4.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut5 = { .fst = c311, .snd = { .fst = o00, .snd = o10, .thd = o20, .f3 = o30 } };
  uint64_t x160 = scrut5.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t reduced_result0 = scrut5.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut6 = { .fst = reduced_result0, .snd = state0 };
  uint64_t y30 = scrut6.snd.f3;
  uint64_t y20 = scrut6.snd.thd;
  uint64_t y10 = scrut6.snd.snd;
  uint64_t y00 = scrut6.snd.fst;
  uint64_t x30 = scrut6.fst.f3;
  uint64_t x20 = scrut6.fst.thd;
  uint64_t x10 = scrut6.fst.snd;
  uint64_t x00 = scrut6.fst.fst;
  uint64_t b4 = (uint64_t)0U;
  uint64_t x210;
  if (x160 == b4)
    x210 = (uint64_t)0U;
  else
    x210 = (uint64_t)18446744073709551615U;
  uint64_t r00 = y00 & x210 | x00 & ~x210;
  uint64_t b5 = (uint64_t)0U;
  uint64_t x211;
  if (x160 == b5)
    x211 = (uint64_t)0U;
  else
    x211 = (uint64_t)18446744073709551615U;
  uint64_t r10 = y10 & x211 | x10 & ~x211;
  uint64_t b6 = (uint64_t)0U;
  uint64_t x212;
  if (x160 == b6)
    x212 = (uint64_t)0U;
  else
    x212 = (uint64_t)18446744073709551615U;
  uint64_t r20 = y20 & x212 | x20 & ~x212;
  uint64_t b7 = (uint64_t)0U;
  uint64_t x213;
  if (x160 == b7)
    x213 = (uint64_t)0U;
  else
    x213 = (uint64_t)18446744073709551615U;
  uint64_t r30 = y30 & x213 | x30 & ~x213;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state0_red = { .fst = r00, .snd = r10, .thd = r20, .f3 = r30 };
  uint32_t c1110 = c_high.f3;
  uint32_t c1210 = c_high.f4;
  uint32_t c1310 = c_high.f5;
  uint32_t c1410 = c_high.f6;
  uint32_t c1510 = c_high.f7;
  uint64_t b01 = (uint64_t)0U;
  uint64_t b11 = Hacl_Spec_P256_Core_store_high_low_u(c1110, (uint32_t)0U);
  uint64_t b21 = Hacl_Spec_P256_Core_store_high_low_u(c1310, c1210);
  uint64_t b31 = Hacl_Spec_P256_Core_store_high_low_u(c1510, c1410);
  K___uint64_t_uint64_t
  scrut7 =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(b01,
      (uint64_t)0xffffffffffffffffU,
      (uint64_t)0U);
  uint64_t o01 = scrut7.fst;
  uint64_t c012 = scrut7.snd;
  K___uint64_t_uint64_t
  scrut8 = Hacl_Spec_Curve25519_Field64_Core_subborrow(b11, (uint64_t)0xffffffffU, c012);
  uint64_t o11 = scrut8.fst;
  uint64_t c162 = scrut8.snd;
  K___uint64_t_uint64_t
  scrut9 = Hacl_Spec_Curve25519_Field64_Core_subborrow(b21, (uint64_t)0U, c162);
  uint64_t o21 = scrut9.fst;
  uint64_t c212 = scrut9.snd;
  K___uint64_t_uint64_t
  scrut10 = Hacl_Spec_Curve25519_Field64_Core_subborrow(b31, (uint64_t)0xffffffff00000001U, c212);
  uint64_t o31 = scrut10.fst;
  uint64_t c312 = scrut10.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut11 = { .fst = c312, .snd = { .fst = o01, .snd = o11, .thd = o21, .f3 = o31 } };
  uint64_t x161 = scrut11.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t reduced_result1 = scrut11.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut12 = { .fst = reduced_result1, .snd = { .fst = b01, .snd = b11, .thd = b21, .f3 = b31 } };
  uint64_t y31 = scrut12.snd.f3;
  uint64_t y21 = scrut12.snd.thd;
  uint64_t y11 = scrut12.snd.snd;
  uint64_t y01 = scrut12.snd.fst;
  uint64_t x31 = scrut12.fst.f3;
  uint64_t x22 = scrut12.fst.thd;
  uint64_t x12 = scrut12.fst.snd;
  uint64_t x01 = scrut12.fst.fst;
  uint64_t b8 = (uint64_t)0U;
  uint64_t x214;
  if (x161 == b8)
    x214 = (uint64_t)0U;
  else
    x214 = (uint64_t)18446744073709551615U;
  uint64_t r03 = y01 & x214 | x01 & ~x214;
  uint64_t b9 = (uint64_t)0U;
  uint64_t x215;
  if (x161 == b9)
    x215 = (uint64_t)0U;
  else
    x215 = (uint64_t)18446744073709551615U;
  uint64_t r12 = y11 & x215 | x12 & ~x215;
  uint64_t b12 = (uint64_t)0U;
  uint64_t x216;
  if (x161 == b12)
    x216 = (uint64_t)0U;
  else
    x216 = (uint64_t)18446744073709551615U;
  uint64_t r21 = y21 & x216 | x22 & ~x216;
  uint64_t b13 = (uint64_t)0U;
  uint64_t x217;
  if (x161 == b13)
    x217 = (uint64_t)0U;
  else
    x217 = (uint64_t)18446744073709551615U;
  uint64_t r31 = y31 & x217 | x31 & ~x217;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state1 = { .fst = r03, .snd = r12, .thd = r21, .f3 = r31 };
  uint32_t c1211 = c_high.f4;
  uint32_t c1311 = c_high.f5;
  uint32_t c1411 = c_high.f6;
  uint32_t c1511 = c_high.f7;
  uint64_t b02 = (uint64_t)0U;
  uint64_t b14 = Hacl_Spec_P256_Core_store_high_low_u(c1211, (uint32_t)0U);
  uint64_t b22 = Hacl_Spec_P256_Core_store_high_low_u(c1411, c1311);
  uint64_t b32 = Hacl_Spec_P256_Core_store_high_low_u((uint32_t)0U, c1511);
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state2 = { .fst = b02, .snd = b14, .thd = b22, .f3 = b32 };
  uint32_t c810 = c_high.fst;
  uint32_t c910 = c_high.snd;
  uint32_t c1010 = c_high.thd;
  uint32_t c1412 = c_high.f6;
  uint32_t c1512 = c_high.f7;
  uint64_t b03 = Hacl_Spec_P256_Core_store_high_low_u(c910, c810);
  uint64_t b15 = Hacl_Spec_P256_Core_store_high_low_u((uint32_t)0U, c1010);
  uint64_t b23 = (uint64_t)0U;
  uint64_t b33 = Hacl_Spec_P256_Core_store_high_low_u(c1512, c1412);
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state3 = { .fst = b03, .snd = b15, .thd = b23, .f3 = b33 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut13 =
    {
      .fst = state3,
      .snd = {
        .fst = (uint64_t)0xffffffffffffffffU,
        .snd = (uint64_t)0xffffffffU,
        .thd = (uint64_t)0U,
        .f3 = (uint64_t)0xffffffff00000001U
      }
    };
  uint64_t f231 = scrut13.snd.f3;
  uint64_t f221 = scrut13.snd.thd;
  uint64_t f211 = scrut13.snd.snd;
  uint64_t f201 = scrut13.snd.fst;
  uint64_t f131 = scrut13.fst.f3;
  uint64_t f121 = scrut13.fst.thd;
  uint64_t f111 = scrut13.fst.snd;
  uint64_t f101 = scrut13.fst.fst;
  K___uint64_t_uint64_t
  scrut14 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f101, f201, (uint64_t)0U);
  uint64_t o02 = scrut14.fst;
  uint64_t c013 = scrut14.snd;
  K___uint64_t_uint64_t scrut15 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f111, f211, c013);
  uint64_t o12 = scrut15.fst;
  uint64_t c163 = scrut15.snd;
  K___uint64_t_uint64_t scrut16 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f121, f221, c163);
  uint64_t o22 = scrut16.fst;
  uint64_t c213 = scrut16.snd;
  K___uint64_t_uint64_t scrut17 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f131, f231, c213);
  uint64_t o32 = scrut17.fst;
  uint64_t c313 = scrut17.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut18 = { .fst = c313, .snd = { .fst = o02, .snd = o12, .thd = o22, .f3 = o32 } };
  uint64_t x162 = scrut18.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t reduced_result2 = scrut18.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut19 = { .fst = reduced_result2, .snd = state3 };
  uint64_t y32 = scrut19.snd.f3;
  uint64_t y22 = scrut19.snd.thd;
  uint64_t y12 = scrut19.snd.snd;
  uint64_t y02 = scrut19.snd.fst;
  uint64_t x32 = scrut19.fst.f3;
  uint64_t x23 = scrut19.fst.thd;
  uint64_t x14 = scrut19.fst.snd;
  uint64_t x02 = scrut19.fst.fst;
  uint64_t b16 = (uint64_t)0U;
  uint64_t x218;
  if (x162 == b16)
    x218 = (uint64_t)0U;
  else
    x218 = (uint64_t)18446744073709551615U;
  uint64_t r04 = y02 & x218 | x02 & ~x218;
  uint64_t b17 = (uint64_t)0U;
  uint64_t x219;
  if (x162 == b17)
    x219 = (uint64_t)0U;
  else
    x219 = (uint64_t)18446744073709551615U;
  uint64_t r13 = y12 & x219 | x14 & ~x219;
  uint64_t b18 = (uint64_t)0U;
  uint64_t x2110;
  if (x162 == b18)
    x2110 = (uint64_t)0U;
  else
    x2110 = (uint64_t)18446744073709551615U;
  uint64_t r22 = y22 & x2110 | x23 & ~x2110;
  uint64_t b19 = (uint64_t)0U;
  uint64_t x2111;
  if (x162 == b19)
    x2111 = (uint64_t)0U;
  else
    x2111 = (uint64_t)18446744073709551615U;
  uint64_t r32 = y32 & x2111 | x32 & ~x2111;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state3_red = { .fst = r04, .snd = r13, .thd = r22, .f3 = r32 };
  uint32_t c811 = c_high.fst;
  uint32_t c911 = c_high.snd;
  uint32_t c1011 = c_high.thd;
  uint32_t c1111 = c_high.f3;
  uint32_t c1312 = c_high.f5;
  uint32_t c1413 = c_high.f6;
  uint32_t c1513 = c_high.f7;
  uint64_t b04 = Hacl_Spec_P256_Core_store_high_low_u(c1011, c911);
  uint64_t b110 = Hacl_Spec_P256_Core_store_high_low_u(c1312, c1111);
  uint64_t b24 = Hacl_Spec_P256_Core_store_high_low_u(c1513, c1413);
  uint64_t b34 = Hacl_Spec_P256_Core_store_high_low_u(c811, c1312);
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state4 = { .fst = b04, .snd = b110, .thd = b24, .f3 = b34 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut20 =
    {
      .fst = state4,
      .snd = {
        .fst = (uint64_t)0xffffffffffffffffU,
        .snd = (uint64_t)0xffffffffU,
        .thd = (uint64_t)0U,
        .f3 = (uint64_t)0xffffffff00000001U
      }
    };
  uint64_t f232 = scrut20.snd.f3;
  uint64_t f222 = scrut20.snd.thd;
  uint64_t f212 = scrut20.snd.snd;
  uint64_t f202 = scrut20.snd.fst;
  uint64_t f132 = scrut20.fst.f3;
  uint64_t f122 = scrut20.fst.thd;
  uint64_t f112 = scrut20.fst.snd;
  uint64_t f102 = scrut20.fst.fst;
  K___uint64_t_uint64_t
  scrut21 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f102, f202, (uint64_t)0U);
  uint64_t o03 = scrut21.fst;
  uint64_t c014 = scrut21.snd;
  K___uint64_t_uint64_t scrut22 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f112, f212, c014);
  uint64_t o13 = scrut22.fst;
  uint64_t c164 = scrut22.snd;
  K___uint64_t_uint64_t scrut23 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f122, f222, c164);
  uint64_t o23 = scrut23.fst;
  uint64_t c214 = scrut23.snd;
  K___uint64_t_uint64_t scrut24 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f132, f232, c214);
  uint64_t o33 = scrut24.fst;
  uint64_t c314 = scrut24.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut25 = { .fst = c314, .snd = { .fst = o03, .snd = o13, .thd = o23, .f3 = o33 } };
  uint64_t x163 = scrut25.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t reduced_result3 = scrut25.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut26 = { .fst = reduced_result3, .snd = state4 };
  uint64_t y33 = scrut26.snd.f3;
  uint64_t y23 = scrut26.snd.thd;
  uint64_t y13 = scrut26.snd.snd;
  uint64_t y03 = scrut26.snd.fst;
  uint64_t x33 = scrut26.fst.f3;
  uint64_t x24 = scrut26.fst.thd;
  uint64_t x17 = scrut26.fst.snd;
  uint64_t x03 = scrut26.fst.fst;
  uint64_t b25 = (uint64_t)0U;
  uint64_t x2112;
  if (x163 == b25)
    x2112 = (uint64_t)0U;
  else
    x2112 = (uint64_t)18446744073709551615U;
  uint64_t r05 = y03 & x2112 | x03 & ~x2112;
  uint64_t b26 = (uint64_t)0U;
  uint64_t x2113;
  if (x163 == b26)
    x2113 = (uint64_t)0U;
  else
    x2113 = (uint64_t)18446744073709551615U;
  uint64_t r14 = y13 & x2113 | x17 & ~x2113;
  uint64_t b27 = (uint64_t)0U;
  uint64_t x2114;
  if (x163 == b27)
    x2114 = (uint64_t)0U;
  else
    x2114 = (uint64_t)18446744073709551615U;
  uint64_t r23 = y23 & x2114 | x24 & ~x2114;
  uint64_t b28 = (uint64_t)0U;
  uint64_t x2115;
  if (x163 == b28)
    x2115 = (uint64_t)0U;
  else
    x2115 = (uint64_t)18446744073709551615U;
  uint64_t r33 = y33 & x2115 | x33 & ~x2115;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state4_red = { .fst = r05, .snd = r14, .thd = r23, .f3 = r33 };
  uint32_t c812 = c_high.fst;
  uint32_t c1012 = c_high.thd;
  uint32_t c1112 = c_high.f3;
  uint32_t c1212 = c_high.f4;
  uint32_t c1313 = c_high.f5;
  uint64_t b05 = Hacl_Spec_P256_Core_store_high_low_u(c1212, c1112);
  uint64_t b111 = Hacl_Spec_P256_Core_store_high_low_u((uint32_t)0U, c1313);
  uint64_t b29 = (uint64_t)0U;
  uint64_t b35 = Hacl_Spec_P256_Core_store_high_low_u(c1012, c812);
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state5 = { .fst = b05, .snd = b111, .thd = b29, .f3 = b35 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut27 =
    {
      .fst = state5,
      .snd = {
        .fst = (uint64_t)0xffffffffffffffffU,
        .snd = (uint64_t)0xffffffffU,
        .thd = (uint64_t)0U,
        .f3 = (uint64_t)0xffffffff00000001U
      }
    };
  uint64_t f233 = scrut27.snd.f3;
  uint64_t f223 = scrut27.snd.thd;
  uint64_t f213 = scrut27.snd.snd;
  uint64_t f203 = scrut27.snd.fst;
  uint64_t f133 = scrut27.fst.f3;
  uint64_t f123 = scrut27.fst.thd;
  uint64_t f113 = scrut27.fst.snd;
  uint64_t f103 = scrut27.fst.fst;
  K___uint64_t_uint64_t
  scrut28 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f103, f203, (uint64_t)0U);
  uint64_t o04 = scrut28.fst;
  uint64_t c015 = scrut28.snd;
  K___uint64_t_uint64_t scrut29 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f113, f213, c015);
  uint64_t o14 = scrut29.fst;
  uint64_t c165 = scrut29.snd;
  K___uint64_t_uint64_t scrut30 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f123, f223, c165);
  uint64_t o24 = scrut30.fst;
  uint64_t c215 = scrut30.snd;
  K___uint64_t_uint64_t scrut31 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f133, f233, c215);
  uint64_t o34 = scrut31.fst;
  uint64_t c315 = scrut31.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut32 = { .fst = c315, .snd = { .fst = o04, .snd = o14, .thd = o24, .f3 = o34 } };
  uint64_t x164 = scrut32.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t reduced_result4 = scrut32.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut33 = { .fst = reduced_result4, .snd = state5 };
  uint64_t y34 = scrut33.snd.f3;
  uint64_t y24 = scrut33.snd.thd;
  uint64_t y14 = scrut33.snd.snd;
  uint64_t y04 = scrut33.snd.fst;
  uint64_t x34 = scrut33.fst.f3;
  uint64_t x25 = scrut33.fst.thd;
  uint64_t x18 = scrut33.fst.snd;
  uint64_t x04 = scrut33.fst.fst;
  uint64_t b36 = (uint64_t)0U;
  uint64_t x2116;
  if (x164 == b36)
    x2116 = (uint64_t)0U;
  else
    x2116 = (uint64_t)18446744073709551615U;
  uint64_t r06 = y04 & x2116 | x04 & ~x2116;
  uint64_t b37 = (uint64_t)0U;
  uint64_t x2117;
  if (x164 == b37)
    x2117 = (uint64_t)0U;
  else
    x2117 = (uint64_t)18446744073709551615U;
  uint64_t r15 = y14 & x2117 | x18 & ~x2117;
  uint64_t b38 = (uint64_t)0U;
  uint64_t x2118;
  if (x164 == b38)
    x2118 = (uint64_t)0U;
  else
    x2118 = (uint64_t)18446744073709551615U;
  uint64_t r24 = y24 & x2118 | x25 & ~x2118;
  uint64_t b39 = (uint64_t)0U;
  uint64_t x2119;
  if (x164 == b39)
    x2119 = (uint64_t)0U;
  else
    x2119 = (uint64_t)18446744073709551615U;
  uint64_t r34 = y34 & x2119 | x34 & ~x2119;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state5_red = { .fst = r06, .snd = r15, .thd = r24, .f3 = r34 };
  uint32_t c912 = c_high.snd;
  uint32_t c1113 = c_high.f3;
  uint32_t c1213 = c_high.f4;
  uint32_t c1314 = c_high.f5;
  uint32_t c1414 = c_high.f6;
  uint32_t c1514 = c_high.f7;
  uint64_t b06 = Hacl_Spec_P256_Core_store_high_low_u(c1314, c1213);
  uint64_t b112 = Hacl_Spec_P256_Core_store_high_low_u(c1514, c1414);
  uint64_t b210 = (uint64_t)0U;
  uint64_t b310 = Hacl_Spec_P256_Core_store_high_low_u(c1113, c912);
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state6 = { .fst = b06, .snd = b112, .thd = b210, .f3 = b310 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut34 =
    {
      .fst = state6,
      .snd = {
        .fst = (uint64_t)0xffffffffffffffffU,
        .snd = (uint64_t)0xffffffffU,
        .thd = (uint64_t)0U,
        .f3 = (uint64_t)0xffffffff00000001U
      }
    };
  uint64_t f234 = scrut34.snd.f3;
  uint64_t f224 = scrut34.snd.thd;
  uint64_t f214 = scrut34.snd.snd;
  uint64_t f204 = scrut34.snd.fst;
  uint64_t f134 = scrut34.fst.f3;
  uint64_t f124 = scrut34.fst.thd;
  uint64_t f114 = scrut34.fst.snd;
  uint64_t f104 = scrut34.fst.fst;
  K___uint64_t_uint64_t
  scrut35 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f104, f204, (uint64_t)0U);
  uint64_t o05 = scrut35.fst;
  uint64_t c016 = scrut35.snd;
  K___uint64_t_uint64_t scrut36 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f114, f214, c016);
  uint64_t o15 = scrut36.fst;
  uint64_t c166 = scrut36.snd;
  K___uint64_t_uint64_t scrut37 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f124, f224, c166);
  uint64_t o25 = scrut37.fst;
  uint64_t c216 = scrut37.snd;
  K___uint64_t_uint64_t scrut38 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f134, f234, c216);
  uint64_t o35 = scrut38.fst;
  uint64_t c316 = scrut38.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut39 = { .fst = c316, .snd = { .fst = o05, .snd = o15, .thd = o25, .f3 = o35 } };
  uint64_t x165 = scrut39.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t reduced_result5 = scrut39.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut40 = { .fst = reduced_result5, .snd = state6 };
  uint64_t y35 = scrut40.snd.f3;
  uint64_t y25 = scrut40.snd.thd;
  uint64_t y15 = scrut40.snd.snd;
  uint64_t y05 = scrut40.snd.fst;
  uint64_t x35 = scrut40.fst.f3;
  uint64_t x26 = scrut40.fst.thd;
  uint64_t x19 = scrut40.fst.snd;
  uint64_t x05 = scrut40.fst.fst;
  uint64_t b40 = (uint64_t)0U;
  uint64_t x2120;
  if (x165 == b40)
    x2120 = (uint64_t)0U;
  else
    x2120 = (uint64_t)18446744073709551615U;
  uint64_t r07 = y05 & x2120 | x05 & ~x2120;
  uint64_t b41 = (uint64_t)0U;
  uint64_t x2121;
  if (x165 == b41)
    x2121 = (uint64_t)0U;
  else
    x2121 = (uint64_t)18446744073709551615U;
  uint64_t r16 = y15 & x2121 | x19 & ~x2121;
  uint64_t b42 = (uint64_t)0U;
  uint64_t x2122;
  if (x165 == b42)
    x2122 = (uint64_t)0U;
  else
    x2122 = (uint64_t)18446744073709551615U;
  uint64_t r25 = y25 & x2122 | x26 & ~x2122;
  uint64_t b43 = (uint64_t)0U;
  uint64_t x2123;
  if (x165 == b43)
    x2123 = (uint64_t)0U;
  else
    x2123 = (uint64_t)18446744073709551615U;
  uint64_t r35 = y35 & x2123 | x35 & ~x2123;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state6_red = { .fst = r07, .snd = r16, .thd = r25, .f3 = r35 };
  uint32_t c81 = c_high.fst;
  uint32_t c913 = c_high.snd;
  uint32_t c1013 = c_high.thd;
  uint32_t c121 = c_high.f4;
  uint32_t c1315 = c_high.f5;
  uint32_t c1415 = c_high.f6;
  uint32_t c1515 = c_high.f7;
  uint64_t b07 = Hacl_Spec_P256_Core_store_high_low_u(c1415, c1315);
  uint64_t b113 = Hacl_Spec_P256_Core_store_high_low_u(c81, c1515);
  uint64_t b211 = Hacl_Spec_P256_Core_store_high_low_u(c1013, c913);
  uint64_t b311 = Hacl_Spec_P256_Core_store_high_low_u(c121, (uint32_t)0U);
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state7 = { .fst = b07, .snd = b113, .thd = b211, .f3 = b311 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut41 =
    {
      .fst = state7,
      .snd = {
        .fst = (uint64_t)0xffffffffffffffffU,
        .snd = (uint64_t)0xffffffffU,
        .thd = (uint64_t)0U,
        .f3 = (uint64_t)0xffffffff00000001U
      }
    };
  uint64_t f235 = scrut41.snd.f3;
  uint64_t f225 = scrut41.snd.thd;
  uint64_t f215 = scrut41.snd.snd;
  uint64_t f205 = scrut41.snd.fst;
  uint64_t f135 = scrut41.fst.f3;
  uint64_t f125 = scrut41.fst.thd;
  uint64_t f115 = scrut41.fst.snd;
  uint64_t f105 = scrut41.fst.fst;
  K___uint64_t_uint64_t
  scrut42 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f105, f205, (uint64_t)0U);
  uint64_t o06 = scrut42.fst;
  uint64_t c017 = scrut42.snd;
  K___uint64_t_uint64_t scrut43 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f115, f215, c017);
  uint64_t o16 = scrut43.fst;
  uint64_t c167 = scrut43.snd;
  K___uint64_t_uint64_t scrut44 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f125, f225, c167);
  uint64_t o26 = scrut44.fst;
  uint64_t c217 = scrut44.snd;
  K___uint64_t_uint64_t scrut45 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f135, f235, c217);
  uint64_t o36 = scrut45.fst;
  uint64_t c317 = scrut45.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut46 = { .fst = c317, .snd = { .fst = o06, .snd = o16, .thd = o26, .f3 = o36 } };
  uint64_t x166 = scrut46.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t reduced_result6 = scrut46.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut47 = { .fst = reduced_result6, .snd = state7 };
  uint64_t y36 = scrut47.snd.f3;
  uint64_t y26 = scrut47.snd.thd;
  uint64_t y16 = scrut47.snd.snd;
  uint64_t y06 = scrut47.snd.fst;
  uint64_t x36 = scrut47.fst.f3;
  uint64_t x27 = scrut47.fst.thd;
  uint64_t x110 = scrut47.fst.snd;
  uint64_t x06 = scrut47.fst.fst;
  uint64_t b44 = (uint64_t)0U;
  uint64_t x2124;
  if (x166 == b44)
    x2124 = (uint64_t)0U;
  else
    x2124 = (uint64_t)18446744073709551615U;
  uint64_t r08 = y06 & x2124 | x06 & ~x2124;
  uint64_t b45 = (uint64_t)0U;
  uint64_t x2125;
  if (x166 == b45)
    x2125 = (uint64_t)0U;
  else
    x2125 = (uint64_t)18446744073709551615U;
  uint64_t r17 = y16 & x2125 | x110 & ~x2125;
  uint64_t b46 = (uint64_t)0U;
  uint64_t x2126;
  if (x166 == b46)
    x2126 = (uint64_t)0U;
  else
    x2126 = (uint64_t)18446744073709551615U;
  uint64_t r26 = y26 & x2126 | x27 & ~x2126;
  uint64_t b47 = (uint64_t)0U;
  uint64_t x2127;
  if (x166 == b47)
    x2127 = (uint64_t)0U;
  else
    x2127 = (uint64_t)18446744073709551615U;
  uint64_t r36 = y36 & x2127 | x36 & ~x2127;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state7_red = { .fst = r08, .snd = r17, .thd = r26, .f3 = r36 };
  uint32_t c91 = c_high.snd;
  uint32_t c101 = c_high.thd;
  uint32_t c111 = c_high.f3;
  uint32_t c131 = c_high.f5;
  uint32_t c141 = c_high.f6;
  uint32_t c151 = c_high.f7;
  uint64_t b08 = Hacl_Spec_P256_Core_store_high_low_u(c151, c141);
  uint64_t b114 = Hacl_Spec_P256_Core_store_high_low_u(c91, (uint32_t)0U);
  uint64_t b212 = Hacl_Spec_P256_Core_store_high_low_u(c111, c101);
  uint64_t b312 = Hacl_Spec_P256_Core_store_high_low_u(c131, (uint32_t)0U);
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state8 = { .fst = b08, .snd = b114, .thd = b212, .f3 = b312 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut48 =
    {
      .fst = state8,
      .snd = {
        .fst = (uint64_t)0xffffffffffffffffU,
        .snd = (uint64_t)0xffffffffU,
        .thd = (uint64_t)0U,
        .f3 = (uint64_t)0xffffffff00000001U
      }
    };
  uint64_t f236 = scrut48.snd.f3;
  uint64_t f226 = scrut48.snd.thd;
  uint64_t f216 = scrut48.snd.snd;
  uint64_t f206 = scrut48.snd.fst;
  uint64_t f136 = scrut48.fst.f3;
  uint64_t f126 = scrut48.fst.thd;
  uint64_t f116 = scrut48.fst.snd;
  uint64_t f106 = scrut48.fst.fst;
  K___uint64_t_uint64_t
  scrut49 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f106, f206, (uint64_t)0U);
  uint64_t o07 = scrut49.fst;
  uint64_t c018 = scrut49.snd;
  K___uint64_t_uint64_t scrut50 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f116, f216, c018);
  uint64_t o17 = scrut50.fst;
  uint64_t c168 = scrut50.snd;
  K___uint64_t_uint64_t scrut51 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f126, f226, c168);
  uint64_t o27 = scrut51.fst;
  uint64_t c218 = scrut51.snd;
  K___uint64_t_uint64_t scrut52 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f136, f236, c218);
  uint64_t o37 = scrut52.fst;
  uint64_t c318 = scrut52.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut53 = { .fst = c318, .snd = { .fst = o07, .snd = o17, .thd = o27, .f3 = o37 } };
  uint64_t x167 = scrut53.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t reduced_result = scrut53.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut54 = { .fst = reduced_result, .snd = state8 };
  uint64_t y3 = scrut54.snd.f3;
  uint64_t y2 = scrut54.snd.thd;
  uint64_t y1 = scrut54.snd.snd;
  uint64_t y0 = scrut54.snd.fst;
  uint64_t x37 = scrut54.fst.f3;
  uint64_t x28 = scrut54.fst.thd;
  uint64_t x111 = scrut54.fst.snd;
  uint64_t x0 = scrut54.fst.fst;
  uint64_t b48 = (uint64_t)0U;
  uint64_t x2128;
  if (x167 == b48)
    x2128 = (uint64_t)0U;
  else
    x2128 = (uint64_t)18446744073709551615U;
  uint64_t r09 = y0 & x2128 | x0 & ~x2128;
  uint64_t b49 = (uint64_t)0U;
  uint64_t x2129;
  if (x167 == b49)
    x2129 = (uint64_t)0U;
  else
    x2129 = (uint64_t)18446744073709551615U;
  uint64_t r18 = y1 & x2129 | x111 & ~x2129;
  uint64_t b50 = (uint64_t)0U;
  uint64_t x2130;
  if (x167 == b50)
    x2130 = (uint64_t)0U;
  else
    x2130 = (uint64_t)18446744073709551615U;
  uint64_t r27 = y2 & x2130 | x28 & ~x2130;
  uint64_t b51 = (uint64_t)0U;
  uint64_t x21;
  if (x167 == b51)
    x21 = (uint64_t)0U;
  else
    x21 = (uint64_t)18446744073709551615U;
  uint64_t r37 = y3 & x21 | x37 & ~x21;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state8_red = { .fst = r09, .snd = r18, .thd = r27, .f3 = r37 };
  uint64_t a00 = state1.fst;
  uint64_t a10 = state1.snd;
  uint64_t a20 = state1.thd;
  uint64_t a30 = state1.f3;
  uint64_t mask0 = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry00;
  if (mask0 < a00)
    carry00 = (uint64_t)1U;
  else
    carry00 = (uint64_t)0U;
  uint64_t carry10;
  if (mask0 < a10)
    carry10 = (uint64_t)1U;
  else
    carry10 = (uint64_t)0U;
  uint64_t carry20;
  if (mask0 < a20)
    carry20 = (uint64_t)1U;
  else
    carry20 = (uint64_t)0U;
  uint64_t carry30;
  if (mask0 < a30)
    carry30 = (uint64_t)1U;
  else
    carry30 = (uint64_t)0U;
  uint64_t a0_updated0 = (a00 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated0 = (a10 << (uint32_t)1U) + carry00;
  uint64_t a2_updated0 = (a20 << (uint32_t)1U) + carry10;
  uint64_t a3_updated0 = (a30 << (uint32_t)1U) + carry20;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state1_2 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry30,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated0,
          .snd = a1_updated0,
          .thd = a2_updated0,
          .f3 = a3_updated0
        }
      ));
  uint64_t a01 = state2.fst;
  uint64_t a11 = state2.snd;
  uint64_t a21 = state2.thd;
  uint64_t a31 = state2.f3;
  uint64_t mask = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry0;
  if (mask < a01)
    carry0 = (uint64_t)1U;
  else
    carry0 = (uint64_t)0U;
  uint64_t carry1;
  if (mask < a11)
    carry1 = (uint64_t)1U;
  else
    carry1 = (uint64_t)0U;
  uint64_t carry2;
  if (mask < a21)
    carry2 = (uint64_t)1U;
  else
    carry2 = (uint64_t)0U;
  uint64_t carry3;
  if (mask < a31)
    carry3 = (uint64_t)1U;
  else
    carry3 = (uint64_t)0U;
  uint64_t a0_updated = (a01 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated = (a11 << (uint32_t)1U) + carry0;
  uint64_t a2_updated = (a21 << (uint32_t)1U) + carry1;
  uint64_t a3_updated = (a31 << (uint32_t)1U) + carry2;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  state2_2 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry3,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated,
          .snd = a1_updated,
          .thd = a2_updated,
          .f3 = a3_updated
        }
      ));
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut55 = { .fst = state0_red, .snd = state1_2 };
  uint64_t b313 = scrut55.snd.f3;
  uint64_t b213 = scrut55.snd.thd;
  uint64_t b115 = scrut55.snd.snd;
  uint64_t b09 = scrut55.snd.fst;
  uint64_t a32 = scrut55.fst.f3;
  uint64_t a22 = scrut55.fst.thd;
  uint64_t a12 = scrut55.fst.snd;
  uint64_t a02 = scrut55.fst.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut56 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a02, .snd = a12, .thd = a22, .f3 = a32 }
      ),
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = b09,
          .snd = b115,
          .thd = b213,
          .f3 = b313
        }
      ));
  uint64_t x70 = scrut56.snd.f3;
  uint64_t x50 = scrut56.snd.thd;
  uint64_t x38 = scrut56.snd.snd;
  uint64_t x112 = scrut56.snd.fst;
  uint64_t x80 = scrut56.fst;
  K___uint64_t_uint64_t
  scrut57 =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x112,
      (uint64_t)0xffffffffffffffffU,
      (uint64_t)0U);
  uint64_t o08 = scrut57.fst;
  uint64_t c019 = scrut57.snd;
  K___uint64_t_uint64_t
  scrut58 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x38, (uint64_t)0xffffffffU, c019);
  uint64_t o18 = scrut58.fst;
  uint64_t c169 = scrut58.snd;
  K___uint64_t_uint64_t
  scrut59 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x50, (uint64_t)0U, c169);
  uint64_t o28 = scrut59.fst;
  uint64_t c219 = scrut59.snd;
  K___uint64_t_uint64_t
  scrut60 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x70, (uint64_t)0xffffffff00000001U, c219);
  uint64_t o38 = scrut60.fst;
  uint64_t c319 = scrut60.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut61 = { .fst = c319, .snd = { .fst = o08, .snd = o18, .thd = o28, .f3 = o38 } };
  uint64_t x150 = scrut61.snd.f3;
  uint64_t x130 = scrut61.snd.thd;
  uint64_t x113 = scrut61.snd.snd;
  uint64_t x90 = scrut61.snd.fst;
  uint64_t x168 = scrut61.fst;
  K___uint64_t_uint64_t
  scrut62 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x80, (uint64_t)0U, x168);
  uint64_t x180 = scrut62.snd;
  uint64_t b52 = (uint64_t)0U;
  uint64_t x29;
  if (x180 == b52)
    x29 = (uint64_t)0U;
  else
    x29 = (uint64_t)18446744073709551615U;
  uint64_t r010 = x112 & x29 | x90 & ~x29;
  uint64_t b53 = (uint64_t)0U;
  uint64_t x220;
  if (x180 == b53)
    x220 = (uint64_t)0U;
  else
    x220 = (uint64_t)18446744073709551615U;
  uint64_t r19 = x38 & x220 | x113 & ~x220;
  uint64_t b54 = (uint64_t)0U;
  uint64_t x221;
  if (x180 == b54)
    x221 = (uint64_t)0U;
  else
    x221 = (uint64_t)18446744073709551615U;
  uint64_t r28 = x50 & x221 | x130 & ~x221;
  uint64_t b55 = (uint64_t)0U;
  uint64_t x222;
  if (x180 == b55)
    x222 = (uint64_t)0U;
  else
    x222 = (uint64_t)18446744073709551615U;
  uint64_t r38 = x70 & x222 | x150 & ~x222;
  uint64_t r0 = r010;
  uint64_t r110 = r19;
  uint64_t r29 = r28;
  uint64_t r39 = r38;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  r011 = { .fst = r0, .snd = r110, .thd = r29, .f3 = r39 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut63 = { .fst = r011, .snd = state2_2 };
  uint64_t b314 = scrut63.snd.f3;
  uint64_t b214 = scrut63.snd.thd;
  uint64_t b116 = scrut63.snd.snd;
  uint64_t b010 = scrut63.snd.fst;
  uint64_t a33 = scrut63.fst.f3;
  uint64_t a23 = scrut63.fst.thd;
  uint64_t a13 = scrut63.fst.snd;
  uint64_t a03 = scrut63.fst.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut64 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a03, .snd = a13, .thd = a23, .f3 = a33 }
      ),
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = b010,
          .snd = b116,
          .thd = b214,
          .f3 = b314
        }
      ));
  uint64_t x71 = scrut64.snd.f3;
  uint64_t x51 = scrut64.snd.thd;
  uint64_t x39 = scrut64.snd.snd;
  uint64_t x114 = scrut64.snd.fst;
  uint64_t x81 = scrut64.fst;
  K___uint64_t_uint64_t
  scrut65 =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x114,
      (uint64_t)0xffffffffffffffffU,
      (uint64_t)0U);
  uint64_t o09 = scrut65.fst;
  uint64_t c0110 = scrut65.snd;
  K___uint64_t_uint64_t
  scrut66 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x39, (uint64_t)0xffffffffU, c0110);
  uint64_t o19 = scrut66.fst;
  uint64_t c1610 = scrut66.snd;
  K___uint64_t_uint64_t
  scrut67 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x51, (uint64_t)0U, c1610);
  uint64_t o29 = scrut67.fst;
  uint64_t c2110 = scrut67.snd;
  K___uint64_t_uint64_t
  scrut68 =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x71,
      (uint64_t)0xffffffff00000001U,
      c2110);
  uint64_t o39 = scrut68.fst;
  uint64_t c3110 = scrut68.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut69 = { .fst = c3110, .snd = { .fst = o09, .snd = o19, .thd = o29, .f3 = o39 } };
  uint64_t x151 = scrut69.snd.f3;
  uint64_t x131 = scrut69.snd.thd;
  uint64_t x115 = scrut69.snd.snd;
  uint64_t x91 = scrut69.snd.fst;
  uint64_t x169 = scrut69.fst;
  K___uint64_t_uint64_t
  scrut70 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x81, (uint64_t)0U, x169);
  uint64_t x181 = scrut70.snd;
  uint64_t b56 = (uint64_t)0U;
  uint64_t x223;
  if (x181 == b56)
    x223 = (uint64_t)0U;
  else
    x223 = (uint64_t)18446744073709551615U;
  uint64_t r012 = x114 & x223 | x91 & ~x223;
  uint64_t b57 = (uint64_t)0U;
  uint64_t x224;
  if (x181 == b57)
    x224 = (uint64_t)0U;
  else
    x224 = (uint64_t)18446744073709551615U;
  uint64_t r111 = x39 & x224 | x115 & ~x224;
  uint64_t b58 = (uint64_t)0U;
  uint64_t x225;
  if (x181 == b58)
    x225 = (uint64_t)0U;
  else
    x225 = (uint64_t)18446744073709551615U;
  uint64_t r210 = x51 & x225 | x131 & ~x225;
  uint64_t b59 = (uint64_t)0U;
  uint64_t x226;
  if (x181 == b59)
    x226 = (uint64_t)0U;
  else
    x226 = (uint64_t)18446744073709551615U;
  uint64_t r310 = x71 & x226 | x151 & ~x226;
  uint64_t r013 = r012;
  uint64_t r1 = r111;
  uint64_t r211 = r210;
  uint64_t r311 = r310;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  r112 = { .fst = r013, .snd = r1, .thd = r211, .f3 = r311 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut71 = { .fst = r112, .snd = state3_red };
  uint64_t b315 = scrut71.snd.f3;
  uint64_t b215 = scrut71.snd.thd;
  uint64_t b117 = scrut71.snd.snd;
  uint64_t b011 = scrut71.snd.fst;
  uint64_t a34 = scrut71.fst.f3;
  uint64_t a24 = scrut71.fst.thd;
  uint64_t a14 = scrut71.fst.snd;
  uint64_t a04 = scrut71.fst.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut72 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a04, .snd = a14, .thd = a24, .f3 = a34 }
      ),
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = b011,
          .snd = b117,
          .thd = b215,
          .f3 = b315
        }
      ));
  uint64_t x72 = scrut72.snd.f3;
  uint64_t x52 = scrut72.snd.thd;
  uint64_t x310 = scrut72.snd.snd;
  uint64_t x116 = scrut72.snd.fst;
  uint64_t x82 = scrut72.fst;
  K___uint64_t_uint64_t
  scrut73 =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x116,
      (uint64_t)0xffffffffffffffffU,
      (uint64_t)0U);
  uint64_t o010 = scrut73.fst;
  uint64_t c0111 = scrut73.snd;
  K___uint64_t_uint64_t
  scrut74 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x310, (uint64_t)0xffffffffU, c0111);
  uint64_t o110 = scrut74.fst;
  uint64_t c1611 = scrut74.snd;
  K___uint64_t_uint64_t
  scrut75 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x52, (uint64_t)0U, c1611);
  uint64_t o210 = scrut75.fst;
  uint64_t c2111 = scrut75.snd;
  K___uint64_t_uint64_t
  scrut76 =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x72,
      (uint64_t)0xffffffff00000001U,
      c2111);
  uint64_t o310 = scrut76.fst;
  uint64_t c3111 = scrut76.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut77 = { .fst = c3111, .snd = { .fst = o010, .snd = o110, .thd = o210, .f3 = o310 } };
  uint64_t x152 = scrut77.snd.f3;
  uint64_t x132 = scrut77.snd.thd;
  uint64_t x117 = scrut77.snd.snd;
  uint64_t x92 = scrut77.snd.fst;
  uint64_t x1610 = scrut77.fst;
  K___uint64_t_uint64_t
  scrut78 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x82, (uint64_t)0U, x1610);
  uint64_t x182 = scrut78.snd;
  uint64_t b60 = (uint64_t)0U;
  uint64_t x227;
  if (x182 == b60)
    x227 = (uint64_t)0U;
  else
    x227 = (uint64_t)18446744073709551615U;
  uint64_t r014 = x116 & x227 | x92 & ~x227;
  uint64_t b61 = (uint64_t)0U;
  uint64_t x228;
  if (x182 == b61)
    x228 = (uint64_t)0U;
  else
    x228 = (uint64_t)18446744073709551615U;
  uint64_t r113 = x310 & x228 | x117 & ~x228;
  uint64_t b62 = (uint64_t)0U;
  uint64_t x229;
  if (x182 == b62)
    x229 = (uint64_t)0U;
  else
    x229 = (uint64_t)18446744073709551615U;
  uint64_t r212 = x52 & x229 | x132 & ~x229;
  uint64_t b63 = (uint64_t)0U;
  uint64_t x230;
  if (x182 == b63)
    x230 = (uint64_t)0U;
  else
    x230 = (uint64_t)18446744073709551615U;
  uint64_t r312 = x72 & x230 | x152 & ~x230;
  uint64_t r01 = r014;
  uint64_t r114 = r113;
  uint64_t r213 = r212;
  uint64_t r313 = r312;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  r015 = { .fst = r01, .snd = r114, .thd = r213, .f3 = r313 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut79 = { .fst = r015, .snd = state4_red };
  uint64_t b3 = scrut79.snd.f3;
  uint64_t b2 = scrut79.snd.thd;
  uint64_t b1 = scrut79.snd.snd;
  uint64_t b0 = scrut79.snd.fst;
  uint64_t a3 = scrut79.fst.f3;
  uint64_t a2 = scrut79.fst.thd;
  uint64_t a1 = scrut79.fst.snd;
  uint64_t a0 = scrut79.fst.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut80 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a0, .snd = a1, .thd = a2, .f3 = a3 }
      ),
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = b0, .snd = b1, .thd = b2, .f3 = b3 }));
  uint64_t x7 = scrut80.snd.f3;
  uint64_t x5 = scrut80.snd.thd;
  uint64_t x3 = scrut80.snd.snd;
  uint64_t x1 = scrut80.snd.fst;
  uint64_t x8 = scrut80.fst;
  K___uint64_t_uint64_t
  scrut =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x1,
      (uint64_t)0xffffffffffffffffU,
      (uint64_t)0U);
  uint64_t o011 = scrut.fst;
  uint64_t c0112 = scrut.snd;
  K___uint64_t_uint64_t
  scrut81 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x3, (uint64_t)0xffffffffU, c0112);
  uint64_t o111 = scrut81.fst;
  uint64_t c1612 = scrut81.snd;
  K___uint64_t_uint64_t
  scrut82 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x5, (uint64_t)0U, c1612);
  uint64_t o211 = scrut82.fst;
  uint64_t c2112 = scrut82.snd;
  K___uint64_t_uint64_t
  scrut83 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x7, (uint64_t)0xffffffff00000001U, c2112);
  uint64_t o311 = scrut83.fst;
  uint64_t c3112 = scrut83.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut84 = { .fst = c3112, .snd = { .fst = o011, .snd = o111, .thd = o211, .f3 = o311 } };
  uint64_t x15 = scrut84.snd.f3;
  uint64_t x13 = scrut84.snd.thd;
  uint64_t x11 = scrut84.snd.snd;
  uint64_t x9 = scrut84.snd.fst;
  uint64_t x16 = scrut84.fst;
  K___uint64_t_uint64_t
  scrut85 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x8, (uint64_t)0U, x16);
  uint64_t x183 = scrut85.snd;
  uint64_t b64 = (uint64_t)0U;
  uint64_t x231;
  if (x183 == b64)
    x231 = (uint64_t)0U;
  else
    x231 = (uint64_t)18446744073709551615U;
  uint64_t r020 = x1 & x231 | x9 & ~x231;
  uint64_t b65 = (uint64_t)0U;
  uint64_t x232;
  if (x183 == b65)
    x232 = (uint64_t)0U;
  else
    x232 = (uint64_t)18446744073709551615U;
  uint64_t r115 = x3 & x232 | x11 & ~x232;
  uint64_t b66 = (uint64_t)0U;
  uint64_t x233;
  if (x183 == b66)
    x233 = (uint64_t)0U;
  else
    x233 = (uint64_t)18446744073709551615U;
  uint64_t r214 = x5 & x233 | x13 & ~x233;
  uint64_t b67 = (uint64_t)0U;
  uint64_t x234;
  if (x183 == b67)
    x234 = (uint64_t)0U;
  else
    x234 = (uint64_t)18446744073709551615U;
  uint64_t r314 = x7 & x234 | x15 & ~x234;
  uint64_t r02 = r020;
  uint64_t r11 = r115;
  uint64_t r2 = r214;
  uint64_t r3 = r314;
  K___uint64_t_uint64_t_uint64_t_uint64_t r116 = { .fst = r02, .snd = r11, .thd = r2, .f3 = r3 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut86 = { .fst = r116, .snd = state5_red };
  uint64_t f237 = scrut86.snd.f3;
  uint64_t f227 = scrut86.snd.thd;
  uint64_t f217 = scrut86.snd.snd;
  uint64_t f207 = scrut86.snd.fst;
  uint64_t f137 = scrut86.fst.f3;
  uint64_t f127 = scrut86.fst.thd;
  uint64_t f117 = scrut86.fst.snd;
  uint64_t f107 = scrut86.fst.fst;
  K___uint64_t_uint64_t
  scrut87 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f107, f207, (uint64_t)0U);
  uint64_t o012 = scrut87.fst;
  uint64_t c0113 = scrut87.snd;
  K___uint64_t_uint64_t scrut88 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f117, f217, c0113);
  uint64_t o112 = scrut88.fst;
  uint64_t c1613 = scrut88.snd;
  K___uint64_t_uint64_t scrut89 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f127, f227, c1613);
  uint64_t o212 = scrut89.fst;
  uint64_t c2113 = scrut89.snd;
  K___uint64_t_uint64_t scrut90 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f137, f237, c2113);
  uint64_t o312 = scrut90.fst;
  uint64_t c3113 = scrut90.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut91 = { .fst = c3113, .snd = { .fst = o012, .snd = o112, .thd = o212, .f3 = o312 } };
  uint64_t c17 = scrut91.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r4 = scrut91.snd;
  uint64_t b68 = (uint64_t)0U;
  uint64_t x235;
  if (c17 == b68)
    x235 = (uint64_t)0U;
  else
    x235 = (uint64_t)18446744073709551615U;
  uint64_t x93 = (uint64_t)0xffffffffffffffffU & x235 | (uint64_t)0U & ~x235;
  uint64_t prime_temp_00 = (uint64_t)0xffffffffffffffffU & x93;
  uint64_t prime_temp_10 = (uint64_t)0xffffffffU & x93;
  uint64_t prime_temp_20 = (uint64_t)0U;
  uint64_t prime_temp_30 = (uint64_t)0xffffffff00000001U & x93;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  prime_temp =
    { .fst = prime_temp_00, .snd = prime_temp_10, .thd = prime_temp_20, .f3 = prime_temp_30 };
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut92 = Hacl_Spec_Curve25519_Field64_Core_add4(prime_temp, r4);
  K___uint64_t_uint64_t_uint64_t_uint64_t r021 = scrut92.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut93 = { .fst = r021, .snd = state6_red };
  uint64_t f238 = scrut93.snd.f3;
  uint64_t f228 = scrut93.snd.thd;
  uint64_t f218 = scrut93.snd.snd;
  uint64_t f208 = scrut93.snd.fst;
  uint64_t f138 = scrut93.fst.f3;
  uint64_t f128 = scrut93.fst.thd;
  uint64_t f118 = scrut93.fst.snd;
  uint64_t f108 = scrut93.fst.fst;
  K___uint64_t_uint64_t
  scrut94 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f108, f208, (uint64_t)0U);
  uint64_t o013 = scrut94.fst;
  uint64_t c0114 = scrut94.snd;
  K___uint64_t_uint64_t scrut95 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f118, f218, c0114);
  uint64_t o113 = scrut95.fst;
  uint64_t c1614 = scrut95.snd;
  K___uint64_t_uint64_t scrut96 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f128, f228, c1614);
  uint64_t o213 = scrut96.fst;
  uint64_t c2114 = scrut96.snd;
  K___uint64_t_uint64_t scrut97 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f138, f238, c2114);
  uint64_t o313 = scrut97.fst;
  uint64_t c3114 = scrut97.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut98 = { .fst = c3114, .snd = { .fst = o013, .snd = o113, .thd = o213, .f3 = o313 } };
  uint64_t c18 = scrut98.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r5 = scrut98.snd;
  uint64_t b69 = (uint64_t)0U;
  uint64_t x236;
  if (c18 == b69)
    x236 = (uint64_t)0U;
  else
    x236 = (uint64_t)18446744073709551615U;
  uint64_t x94 = (uint64_t)0xffffffffffffffffU & x236 | (uint64_t)0U & ~x236;
  uint64_t prime_temp_01 = (uint64_t)0xffffffffffffffffU & x94;
  uint64_t prime_temp_11 = (uint64_t)0xffffffffU & x94;
  uint64_t prime_temp_21 = (uint64_t)0U;
  uint64_t prime_temp_31 = (uint64_t)0xffffffff00000001U & x94;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  prime_temp0 =
    { .fst = prime_temp_01, .snd = prime_temp_11, .thd = prime_temp_21, .f3 = prime_temp_31 };
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut99 = Hacl_Spec_Curve25519_Field64_Core_add4(prime_temp0, r5);
  K___uint64_t_uint64_t_uint64_t_uint64_t r120 = scrut99.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut100 = { .fst = r120, .snd = state7_red };
  uint64_t f239 = scrut100.snd.f3;
  uint64_t f229 = scrut100.snd.thd;
  uint64_t f219 = scrut100.snd.snd;
  uint64_t f209 = scrut100.snd.fst;
  uint64_t f139 = scrut100.fst.f3;
  uint64_t f129 = scrut100.fst.thd;
  uint64_t f119 = scrut100.fst.snd;
  uint64_t f109 = scrut100.fst.fst;
  K___uint64_t_uint64_t
  scrut101 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f109, f209, (uint64_t)0U);
  uint64_t o014 = scrut101.fst;
  uint64_t c0115 = scrut101.snd;
  K___uint64_t_uint64_t
  scrut102 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f119, f219, c0115);
  uint64_t o114 = scrut102.fst;
  uint64_t c1615 = scrut102.snd;
  K___uint64_t_uint64_t
  scrut103 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f129, f229, c1615);
  uint64_t o214 = scrut103.fst;
  uint64_t c2115 = scrut103.snd;
  K___uint64_t_uint64_t
  scrut104 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f139, f239, c2115);
  uint64_t o314 = scrut104.fst;
  uint64_t c3115 = scrut104.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut105 = { .fst = c3115, .snd = { .fst = o014, .snd = o114, .thd = o214, .f3 = o314 } };
  uint64_t c19 = scrut105.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r6 = scrut105.snd;
  uint64_t b70 = (uint64_t)0U;
  uint64_t x237;
  if (c19 == b70)
    x237 = (uint64_t)0U;
  else
    x237 = (uint64_t)18446744073709551615U;
  uint64_t x95 = (uint64_t)0xffffffffffffffffU & x237 | (uint64_t)0U & ~x237;
  uint64_t prime_temp_02 = (uint64_t)0xffffffffffffffffU & x95;
  uint64_t prime_temp_12 = (uint64_t)0xffffffffU & x95;
  uint64_t prime_temp_22 = (uint64_t)0U;
  uint64_t prime_temp_32 = (uint64_t)0xffffffff00000001U & x95;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  prime_temp1 =
    { .fst = prime_temp_02, .snd = prime_temp_12, .thd = prime_temp_22, .f3 = prime_temp_32 };
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut106 = Hacl_Spec_Curve25519_Field64_Core_add4(prime_temp1, r6);
  K___uint64_t_uint64_t_uint64_t_uint64_t r030 = scrut106.snd;
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut107 = { .fst = r030, .snd = state8_red };
  uint64_t f23 = scrut107.snd.f3;
  uint64_t f22 = scrut107.snd.thd;
  uint64_t f21 = scrut107.snd.snd;
  uint64_t f20 = scrut107.snd.fst;
  uint64_t f13 = scrut107.fst.f3;
  uint64_t f12 = scrut107.fst.thd;
  uint64_t f11 = scrut107.fst.snd;
  uint64_t f10 = scrut107.fst.fst;
  K___uint64_t_uint64_t
  scrut108 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f10, f20, (uint64_t)0U);
  uint64_t o0 = scrut108.fst;
  uint64_t c01 = scrut108.snd;
  K___uint64_t_uint64_t scrut109 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f11, f21, c01);
  uint64_t o1 = scrut109.fst;
  uint64_t c16 = scrut109.snd;
  K___uint64_t_uint64_t scrut110 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f12, f22, c16);
  uint64_t o2 = scrut110.fst;
  uint64_t c21 = scrut110.snd;
  K___uint64_t_uint64_t scrut111 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f13, f23, c21);
  uint64_t o3 = scrut111.fst;
  uint64_t c31 = scrut111.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut112 = { .fst = c31, .snd = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 } };
  uint64_t c = scrut112.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r = scrut112.snd;
  uint64_t b = (uint64_t)0U;
  uint64_t x2;
  if (c == b)
    x2 = (uint64_t)0U;
  else
    x2 = (uint64_t)18446744073709551615U;
  uint64_t x96 = (uint64_t)0xffffffffffffffffU & x2 | (uint64_t)0U & ~x2;
  uint64_t prime_temp_0 = (uint64_t)0xffffffffffffffffU & x96;
  uint64_t prime_temp_1 = (uint64_t)0xffffffffU & x96;
  uint64_t prime_temp_2 = (uint64_t)0U;
  uint64_t prime_temp_3 = (uint64_t)0xffffffff00000001U & x96;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  prime_temp2 =
    { .fst = prime_temp_0, .snd = prime_temp_1, .thd = prime_temp_2, .f3 = prime_temp_3 };
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut113 = Hacl_Spec_Curve25519_Field64_Core_add4(prime_temp2, r);
  K___uint64_t_uint64_t_uint64_t_uint64_t result = scrut113.snd;
  return result;
}

static void
Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(
  uint64_t *a,
  uint64_t *b,
  uint64_t *r
)
{
  uint64_t a0 = a[0U];
  uint64_t a1 = a[1U];
  uint64_t a2 = a[2U];
  uint64_t a3 = a[3U];
  uint64_t b0 = b[0U];
  uint64_t b1 = b[1U];
  uint64_t b2 = b[2U];
  uint64_t b3 = b[3U];
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut =
    Hacl_Spec_P256_Core_montgomery_multiplication((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a0, .snd = a1, .thd = a2, .f3 = a3 }
      ),
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = b0, .snd = b1, .thd = b2, .f3 = b3 }));
  uint64_t r0 = scrut.fst;
  uint64_t r1 = scrut.snd;
  uint64_t r2 = scrut.thd;
  uint64_t r3 = scrut.f3;
  r[0U] = r0;
  r[1U] = r1;
  r[2U] = r2;
  r[3U] = r3;
}

static void Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowN(uint32_t n1, uint64_t *a)
{
  for (uint32_t i = (uint32_t)0U; i < n1; i = i + (uint32_t)1U)
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(a, a, a);
}

static void
Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowNminusOne(
  uint32_t n1,
  uint64_t *a,
  uint64_t *b
)
{
  b[0U] = (uint64_t)1U;
  b[1U] = (uint64_t)18446744069414584320U;
  b[2U] = (uint64_t)18446744073709551615U;
  b[3U] = (uint64_t)4294967294U;
  for (uint32_t i = (uint32_t)0U; i < n1; i = i + (uint32_t)1U)
  {
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(b, a, b);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(a, a, a);
  }
}

static void
Hacl_Spec_P256_MontgomeryMultiplication_exponent(
  uint64_t *a,
  uint64_t *result,
  uint64_t *tempBuffer
)
{
  uint64_t *buffer_norm_1 = tempBuffer;
  uint64_t *buffer_result1 = tempBuffer + (uint32_t)4U;
  uint64_t *buffer_result2 = tempBuffer + (uint32_t)8U;
  uint64_t *buffer_norm_3 = tempBuffer + (uint32_t)12U;
  uint64_t *buffer_result3 = tempBuffer + (uint32_t)16U;
  memcpy(buffer_norm_1, a, (uint32_t)4U * sizeof a[0U]);
  uint64_t *buffer_a = buffer_norm_1;
  uint64_t *buffer_b0 = buffer_norm_1 + (uint32_t)4U;
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowNminusOne((uint32_t)32U,
    buffer_a,
    buffer_b0);
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowN((uint32_t)224U, buffer_b0);
  memcpy(buffer_result2, a, (uint32_t)4U * sizeof a[0U]);
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowN((uint32_t)192U, buffer_result2);
  memcpy(buffer_norm_3, a, (uint32_t)4U * sizeof a[0U]);
  uint64_t *buffer_a0 = buffer_norm_3;
  uint64_t *buffer_b = buffer_norm_3 + (uint32_t)4U;
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowNminusOne((uint32_t)94U,
    buffer_a0,
    buffer_b);
  Hacl_Spec_P256_MontgomeryMultiplication_fsquarePowN((uint32_t)2U, buffer_b);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(buffer_result1,
    buffer_result2,
    buffer_result1);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(buffer_result1,
    buffer_result3,
    buffer_result1);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(buffer_result1,
    a,
    buffer_result1);
  memcpy(result, buffer_result1, (uint32_t)4U * sizeof buffer_result1[0U]);
}

static void
Hacl_Spec_P256_MontgomeryMultiplication_cswap(uint64_t bit, uint64_t *p1, uint64_t *p2)
{
  uint64_t mask = (uint64_t)0U - bit;
  for (uint32_t i = (uint32_t)0U; i < (uint32_t)12U; i = i + (uint32_t)1U)
  {
    uint64_t dummy = mask & (p1[i] ^ p2[i]);
    p1[i] = p1[i] ^ dummy;
    p2[i] = p2[i] ^ dummy;
  }
}

static void p256_add(uint64_t *arg1, uint64_t *arg2, uint64_t *out)
{
  uint64_t arg1_0 = arg1[0U];
  uint64_t arg1_1 = arg1[1U];
  uint64_t arg1_2 = arg1[2U];
  uint64_t arg1_3 = arg1[3U];
  uint64_t arg2_0 = arg2[0U];
  uint64_t arg2_1 = arg2[1U];
  uint64_t arg2_2 = arg2[2U];
  uint64_t arg2_3 = arg2[3U];
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = arg1_0,
          .snd = arg1_1,
          .thd = arg1_2,
          .f3 = arg1_3
        }
      ),
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = arg2_0,
          .snd = arg2_1,
          .thd = arg2_2,
          .f3 = arg2_3
        }
      ));
  uint64_t x7 = scrut0.snd.f3;
  uint64_t x5 = scrut0.snd.thd;
  uint64_t x3 = scrut0.snd.snd;
  uint64_t x1 = scrut0.snd.fst;
  uint64_t x8 = scrut0.fst;
  K___uint64_t_uint64_t
  scrut =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x1,
      (uint64_t)0xffffffffffffffffU,
      (uint64_t)0U);
  uint64_t o0 = scrut.fst;
  uint64_t c0 = scrut.snd;
  K___uint64_t_uint64_t
  scrut1 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x3, (uint64_t)0xffffffffU, c0);
  uint64_t o1 = scrut1.fst;
  uint64_t c1 = scrut1.snd;
  K___uint64_t_uint64_t
  scrut2 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x5, (uint64_t)0U, c1);
  uint64_t o2 = scrut2.fst;
  uint64_t c2 = scrut2.snd;
  K___uint64_t_uint64_t
  scrut3 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x7, (uint64_t)0xffffffff00000001U, c2);
  uint64_t o3 = scrut3.fst;
  uint64_t c3 = scrut3.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut4 = { .fst = c3, .snd = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 } };
  uint64_t x15 = scrut4.snd.f3;
  uint64_t x13 = scrut4.snd.thd;
  uint64_t x11 = scrut4.snd.snd;
  uint64_t x9 = scrut4.snd.fst;
  uint64_t x16 = scrut4.fst;
  K___uint64_t_uint64_t
  scrut5 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x8, (uint64_t)0U, x16);
  uint64_t x18 = scrut5.snd;
  uint64_t b0 = (uint64_t)0U;
  uint64_t x20;
  if (x18 == b0)
    x20 = (uint64_t)0U;
  else
    x20 = (uint64_t)18446744073709551615U;
  uint64_t r00 = x1 & x20 | x9 & ~x20;
  uint64_t b1 = (uint64_t)0U;
  uint64_t x21;
  if (x18 == b1)
    x21 = (uint64_t)0U;
  else
    x21 = (uint64_t)18446744073709551615U;
  uint64_t r10 = x3 & x21 | x11 & ~x21;
  uint64_t b2 = (uint64_t)0U;
  uint64_t x22;
  if (x18 == b2)
    x22 = (uint64_t)0U;
  else
    x22 = (uint64_t)18446744073709551615U;
  uint64_t r20 = x5 & x22 | x13 & ~x22;
  uint64_t b = (uint64_t)0U;
  uint64_t x2;
  if (x18 == b)
    x2 = (uint64_t)0U;
  else
    x2 = (uint64_t)18446744073709551615U;
  uint64_t r30 = x7 & x2 | x15 & ~x2;
  uint64_t r01 = r00;
  uint64_t r11 = r10;
  uint64_t r21 = r20;
  uint64_t r31 = r30;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut6 = { .fst = r01, .snd = r11, .thd = r21, .f3 = r31 };
  uint64_t r0 = scrut6.fst;
  uint64_t r1 = scrut6.snd;
  uint64_t r2 = scrut6.thd;
  uint64_t r3 = scrut6.f3;
  out[0U] = r0;
  out[1U] = r1;
  out[2U] = r2;
  out[3U] = r3;
}

static void p256_sub(uint64_t *arg1, uint64_t *arg2, uint64_t *out)
{
  uint64_t arg1_0 = arg1[0U];
  uint64_t arg1_1 = arg1[1U];
  uint64_t arg1_2 = arg1[2U];
  uint64_t arg1_3 = arg1[3U];
  uint64_t arg2_0 = arg2[0U];
  uint64_t arg2_1 = arg2[1U];
  uint64_t arg2_2 = arg2[2U];
  uint64_t arg2_3 = arg2[3U];
  K___uint64_t_uint64_t_uint64_t_uint64_t
  a = { .fst = arg1_0, .snd = arg1_1, .thd = arg1_2, .f3 = arg1_3 };
  K___uint64_t_uint64_t_uint64_t_uint64_t
  b = { .fst = arg2_0, .snd = arg2_1, .thd = arg2_2, .f3 = arg2_3 };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut = { .fst = a, .snd = b };
  uint64_t f23 = scrut.snd.f3;
  uint64_t f22 = scrut.snd.thd;
  uint64_t f21 = scrut.snd.snd;
  uint64_t f20 = scrut.snd.fst;
  uint64_t f13 = scrut.fst.f3;
  uint64_t f12 = scrut.fst.thd;
  uint64_t f11 = scrut.fst.snd;
  uint64_t f10 = scrut.fst.fst;
  K___uint64_t_uint64_t
  scrut0 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f10, f20, (uint64_t)0U);
  uint64_t o0 = scrut0.fst;
  uint64_t c0 = scrut0.snd;
  K___uint64_t_uint64_t scrut1 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f11, f21, c0);
  uint64_t o1 = scrut1.fst;
  uint64_t c1 = scrut1.snd;
  K___uint64_t_uint64_t scrut2 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f12, f22, c1);
  uint64_t o2 = scrut2.fst;
  uint64_t c2 = scrut2.snd;
  K___uint64_t_uint64_t scrut3 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f13, f23, c2);
  uint64_t o3 = scrut3.fst;
  uint64_t c3 = scrut3.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut4 = { .fst = c3, .snd = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 } };
  uint64_t c = scrut4.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r = scrut4.snd;
  uint64_t b1 = (uint64_t)0U;
  uint64_t x2;
  if (c == b1)
    x2 = (uint64_t)0U;
  else
    x2 = (uint64_t)18446744073709551615U;
  uint64_t x9 = (uint64_t)0xffffffffffffffffU & x2 | (uint64_t)0U & ~x2;
  uint64_t prime_temp_0 = (uint64_t)0xffffffffffffffffU & x9;
  uint64_t prime_temp_1 = (uint64_t)0xffffffffU & x9;
  uint64_t prime_temp_2 = (uint64_t)0U;
  uint64_t prime_temp_3 = (uint64_t)0xffffffff00000001U & x9;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  prime_temp =
    { .fst = prime_temp_0, .snd = prime_temp_1, .thd = prime_temp_2, .f3 = prime_temp_3 };
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut5 = Hacl_Spec_Curve25519_Field64_Core_add4(prime_temp, r);
  K___uint64_t_uint64_t_uint64_t_uint64_t scrut6 = scrut5.snd;
  uint64_t r0 = scrut6.fst;
  uint64_t r1 = scrut6.snd;
  uint64_t r2 = scrut6.thd;
  uint64_t r3 = scrut6.f3;
  out[0U] = r0;
  out[1U] = r1;
  out[2U] = r2;
  out[3U] = r3;
}

void pointToDomain(uint64_t *p, uint64_t *result)
{
  uint64_t *p_x = p;
  uint64_t *p_y = p + (uint32_t)4U;
  uint64_t *p_z = p + (uint32_t)8U;
  uint64_t *r_x = result;
  uint64_t *r_y = result + (uint32_t)4U;
  uint64_t *r_z = result + (uint32_t)8U;
  uint64_t value0 = p_x[0U];
  uint64_t value10 = p_x[1U];
  uint64_t value20 = p_x[2U];
  uint64_t value30 = p_x[3U];
  uint64_t c00 = value0;
  uint64_t c10 = value10;
  uint64_t c20 = value20;
  uint64_t c30 = value30;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  multipliedByPow256 =
    {
      .fst = (uint64_t)0U, .snd = (uint64_t)0U, .thd = (uint64_t)0U, .f3 = (uint64_t)0U, .f4 = c00,
      .f5 = c10, .f6 = c20, .f7 = c30
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut = Hacl_Spec_P256_SolinasReduction_solinas_reduction(multipliedByPow256);
  uint64_t r00 = scrut.fst;
  uint64_t r10 = scrut.snd;
  uint64_t r20 = scrut.thd;
  uint64_t r30 = scrut.f3;
  r_x[0U] = r00;
  r_x[1U] = r10;
  r_x[2U] = r20;
  r_x[3U] = r30;
  uint64_t value00 = p_y[0U];
  uint64_t value11 = p_y[1U];
  uint64_t value21 = p_y[2U];
  uint64_t value31 = p_y[3U];
  uint64_t c01 = value00;
  uint64_t c11 = value11;
  uint64_t c21 = value21;
  uint64_t c31 = value31;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  multipliedByPow2560 =
    {
      .fst = (uint64_t)0U, .snd = (uint64_t)0U, .thd = (uint64_t)0U, .f3 = (uint64_t)0U, .f4 = c01,
      .f5 = c11, .f6 = c21, .f7 = c31
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 = Hacl_Spec_P256_SolinasReduction_solinas_reduction(multipliedByPow2560);
  uint64_t r01 = scrut0.fst;
  uint64_t r11 = scrut0.snd;
  uint64_t r21 = scrut0.thd;
  uint64_t r31 = scrut0.f3;
  r_y[0U] = r01;
  r_y[1U] = r11;
  r_y[2U] = r21;
  r_y[3U] = r31;
  uint64_t value01 = p_z[0U];
  uint64_t value1 = p_z[1U];
  uint64_t value2 = p_z[2U];
  uint64_t value3 = p_z[3U];
  uint64_t c0 = value01;
  uint64_t c1 = value1;
  uint64_t c2 = value2;
  uint64_t c3 = value3;
  K___uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t_uint64_t
  multipliedByPow2561 =
    {
      .fst = (uint64_t)0U, .snd = (uint64_t)0U, .thd = (uint64_t)0U, .f3 = (uint64_t)0U, .f4 = c0,
      .f5 = c1, .f6 = c2, .f7 = c3
    };
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut1 = Hacl_Spec_P256_SolinasReduction_solinas_reduction(multipliedByPow2561);
  uint64_t r0 = scrut1.fst;
  uint64_t r1 = scrut1.snd;
  uint64_t r2 = scrut1.thd;
  uint64_t r3 = scrut1.f3;
  r_z[0U] = r0;
  r_z[1U] = r1;
  r_z[2U] = r2;
  r_z[3U] = r3;
}

static void fromDomain(uint64_t *f, uint64_t *result)
{
  uint64_t b0 = f[0U];
  uint64_t b1 = f[1U];
  uint64_t b2 = f[2U];
  uint64_t b3 = f[3U];
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut =
    Hacl_Spec_P256_Core_montgomery_multiplication((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = (uint64_t)1U,
          .snd = (uint64_t)0U,
          .thd = (uint64_t)0U,
          .f3 = (uint64_t)0U
        }
      ),
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = b0, .snd = b1, .thd = b2, .f3 = b3 }));
  uint64_t r0 = scrut.fst;
  uint64_t r1 = scrut.snd;
  uint64_t r2 = scrut.thd;
  uint64_t r3 = scrut.f3;
  result[0U] = r0;
  result[1U] = r1;
  result[2U] = r2;
  result[3U] = r3;
}

void pointFromDomain(uint64_t *p, uint64_t *result)
{
  uint64_t *p_x = p;
  uint64_t *p_y = p + (uint32_t)4U;
  uint64_t *p_z = p + (uint32_t)8U;
  uint64_t *r_x = result;
  uint64_t *r_y = result + (uint32_t)4U;
  uint64_t *r_z = result + (uint32_t)8U;
  fromDomain(p_x, r_x);
  fromDomain(p_y, r_y);
  fromDomain(p_z, r_z);
}

static void quatre(uint64_t *a, uint64_t *result)
{
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(a, a, result);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(result,
    result,
    result);
}

static void multByTwo(uint64_t *a, uint64_t *result)
{
  uint64_t a0 = a[0U];
  uint64_t a1 = a[1U];
  uint64_t a2 = a[2U];
  uint64_t a3 = a[3U];
  uint64_t a01 = a0;
  uint64_t a11 = a1;
  uint64_t a21 = a2;
  uint64_t a31 = a3;
  uint64_t mask = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry0;
  if (mask < a01)
    carry0 = (uint64_t)1U;
  else
    carry0 = (uint64_t)0U;
  uint64_t carry1;
  if (mask < a11)
    carry1 = (uint64_t)1U;
  else
    carry1 = (uint64_t)0U;
  uint64_t carry2;
  if (mask < a21)
    carry2 = (uint64_t)1U;
  else
    carry2 = (uint64_t)0U;
  uint64_t carry3;
  if (mask < a31)
    carry3 = (uint64_t)1U;
  else
    carry3 = (uint64_t)0U;
  uint64_t a0_updated = (a01 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated = (a11 << (uint32_t)1U) + carry0;
  uint64_t a2_updated = (a21 << (uint32_t)1U) + carry1;
  uint64_t a3_updated = (a31 << (uint32_t)1U) + carry2;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry3,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated,
          .snd = a1_updated,
          .thd = a2_updated,
          .f3 = a3_updated
        }
      ));
  uint64_t r0 = scrut.fst;
  uint64_t r1 = scrut.snd;
  uint64_t r2 = scrut.thd;
  uint64_t r3 = scrut.f3;
  result[0U] = r0;
  result[1U] = r1;
  result[2U] = r2;
  result[3U] = r3;
}

static void multByThree(uint64_t *a, uint64_t *result)
{
  uint64_t a0 = a[0U];
  uint64_t a1 = a[1U];
  uint64_t a2 = a[2U];
  uint64_t a3 = a[3U];
  uint64_t a010 = a0;
  uint64_t a110 = a1;
  uint64_t a210 = a2;
  uint64_t a310 = a3;
  uint64_t mask = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry0;
  if (mask < a010)
    carry0 = (uint64_t)1U;
  else
    carry0 = (uint64_t)0U;
  uint64_t carry1;
  if (mask < a110)
    carry1 = (uint64_t)1U;
  else
    carry1 = (uint64_t)0U;
  uint64_t carry2;
  if (mask < a210)
    carry2 = (uint64_t)1U;
  else
    carry2 = (uint64_t)0U;
  uint64_t carry3;
  if (mask < a310)
    carry3 = (uint64_t)1U;
  else
    carry3 = (uint64_t)0U;
  uint64_t a0_updated = (a010 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated = (a110 << (uint32_t)1U) + carry0;
  uint64_t a2_updated = (a210 << (uint32_t)1U) + carry1;
  uint64_t a3_updated = (a310 << (uint32_t)1U) + carry2;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  multByTwo1 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry3,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated,
          .snd = a1_updated,
          .thd = a2_updated,
          .f3 = a3_updated
        }
      ));
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 = { .fst = multByTwo1, .snd = { .fst = a0, .snd = a1, .thd = a2, .f3 = a3 } };
  uint64_t b3 = scrut0.snd.f3;
  uint64_t b2 = scrut0.snd.thd;
  uint64_t b1 = scrut0.snd.snd;
  uint64_t b0 = scrut0.snd.fst;
  uint64_t a31 = scrut0.fst.f3;
  uint64_t a21 = scrut0.fst.thd;
  uint64_t a11 = scrut0.fst.snd;
  uint64_t a01 = scrut0.fst.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut1 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a01, .snd = a11, .thd = a21, .f3 = a31 }
      ),
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = b0, .snd = b1, .thd = b2, .f3 = b3 }));
  uint64_t x7 = scrut1.snd.f3;
  uint64_t x5 = scrut1.snd.thd;
  uint64_t x3 = scrut1.snd.snd;
  uint64_t x1 = scrut1.snd.fst;
  uint64_t x8 = scrut1.fst;
  K___uint64_t_uint64_t
  scrut =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x1,
      (uint64_t)0xffffffffffffffffU,
      (uint64_t)0U);
  uint64_t o0 = scrut.fst;
  uint64_t c0 = scrut.snd;
  K___uint64_t_uint64_t
  scrut2 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x3, (uint64_t)0xffffffffU, c0);
  uint64_t o1 = scrut2.fst;
  uint64_t c1 = scrut2.snd;
  K___uint64_t_uint64_t
  scrut3 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x5, (uint64_t)0U, c1);
  uint64_t o2 = scrut3.fst;
  uint64_t c2 = scrut3.snd;
  K___uint64_t_uint64_t
  scrut4 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x7, (uint64_t)0xffffffff00000001U, c2);
  uint64_t o3 = scrut4.fst;
  uint64_t c3 = scrut4.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut5 = { .fst = c3, .snd = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 } };
  uint64_t x15 = scrut5.snd.f3;
  uint64_t x13 = scrut5.snd.thd;
  uint64_t x11 = scrut5.snd.snd;
  uint64_t x9 = scrut5.snd.fst;
  uint64_t x16 = scrut5.fst;
  K___uint64_t_uint64_t
  scrut6 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x8, (uint64_t)0U, x16);
  uint64_t x18 = scrut6.snd;
  uint64_t b4 = (uint64_t)0U;
  uint64_t x20;
  if (x18 == b4)
    x20 = (uint64_t)0U;
  else
    x20 = (uint64_t)18446744073709551615U;
  uint64_t r00 = x1 & x20 | x9 & ~x20;
  uint64_t b5 = (uint64_t)0U;
  uint64_t x21;
  if (x18 == b5)
    x21 = (uint64_t)0U;
  else
    x21 = (uint64_t)18446744073709551615U;
  uint64_t r10 = x3 & x21 | x11 & ~x21;
  uint64_t b6 = (uint64_t)0U;
  uint64_t x22;
  if (x18 == b6)
    x22 = (uint64_t)0U;
  else
    x22 = (uint64_t)18446744073709551615U;
  uint64_t r20 = x5 & x22 | x13 & ~x22;
  uint64_t b = (uint64_t)0U;
  uint64_t x2;
  if (x18 == b)
    x2 = (uint64_t)0U;
  else
    x2 = (uint64_t)18446744073709551615U;
  uint64_t r30 = x7 & x2 | x15 & ~x2;
  uint64_t r01 = r00;
  uint64_t r11 = r10;
  uint64_t r21 = r20;
  uint64_t r31 = r30;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  byThree = { .fst = r01, .snd = r11, .thd = r21, .f3 = r31 };
  uint64_t r0 = byThree.fst;
  uint64_t r1 = byThree.snd;
  uint64_t r2 = byThree.thd;
  uint64_t r3 = byThree.f3;
  result[0U] = r0;
  result[1U] = r1;
  result[2U] = r2;
  result[3U] = r3;
}

static void multByFour(uint64_t *a, uint64_t *result)
{
  uint64_t a0 = a[0U];
  uint64_t a1 = a[1U];
  uint64_t a2 = a[2U];
  uint64_t a3 = a[3U];
  uint64_t a010 = a0;
  uint64_t a110 = a1;
  uint64_t a210 = a2;
  uint64_t a310 = a3;
  uint64_t mask0 = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry00;
  if (mask0 < a010)
    carry00 = (uint64_t)1U;
  else
    carry00 = (uint64_t)0U;
  uint64_t carry10;
  if (mask0 < a110)
    carry10 = (uint64_t)1U;
  else
    carry10 = (uint64_t)0U;
  uint64_t carry20;
  if (mask0 < a210)
    carry20 = (uint64_t)1U;
  else
    carry20 = (uint64_t)0U;
  uint64_t carry30;
  if (mask0 < a310)
    carry30 = (uint64_t)1U;
  else
    carry30 = (uint64_t)0U;
  uint64_t a0_updated0 = (a010 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated0 = (a110 << (uint32_t)1U) + carry00;
  uint64_t a2_updated0 = (a210 << (uint32_t)1U) + carry10;
  uint64_t a3_updated0 = (a310 << (uint32_t)1U) + carry20;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  multByTwo1 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry30,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated0,
          .snd = a1_updated0,
          .thd = a2_updated0,
          .f3 = a3_updated0
        }
      ));
  uint64_t a01 = multByTwo1.fst;
  uint64_t a11 = multByTwo1.snd;
  uint64_t a21 = multByTwo1.thd;
  uint64_t a31 = multByTwo1.f3;
  uint64_t mask = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry0;
  if (mask < a01)
    carry0 = (uint64_t)1U;
  else
    carry0 = (uint64_t)0U;
  uint64_t carry1;
  if (mask < a11)
    carry1 = (uint64_t)1U;
  else
    carry1 = (uint64_t)0U;
  uint64_t carry2;
  if (mask < a21)
    carry2 = (uint64_t)1U;
  else
    carry2 = (uint64_t)0U;
  uint64_t carry3;
  if (mask < a31)
    carry3 = (uint64_t)1U;
  else
    carry3 = (uint64_t)0U;
  uint64_t a0_updated = (a01 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated = (a11 << (uint32_t)1U) + carry0;
  uint64_t a2_updated = (a21 << (uint32_t)1U) + carry1;
  uint64_t a3_updated = (a31 << (uint32_t)1U) + carry2;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  multByFour =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry3,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated,
          .snd = a1_updated,
          .thd = a2_updated,
          .f3 = a3_updated
        }
      ));
  uint64_t r0 = multByFour.fst;
  uint64_t r1 = multByFour.snd;
  uint64_t r2 = multByFour.thd;
  uint64_t r3 = multByFour.f3;
  result[0U] = r0;
  result[1U] = r1;
  result[2U] = r2;
  result[3U] = r3;
}

static void multByEight(uint64_t *a, uint64_t *result)
{
  uint64_t a0 = a[0U];
  uint64_t a1 = a[1U];
  uint64_t a2 = a[2U];
  uint64_t a3 = a[3U];
  uint64_t a010 = a0;
  uint64_t a110 = a1;
  uint64_t a210 = a2;
  uint64_t a310 = a3;
  uint64_t mask0 = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry00;
  if (mask0 < a010)
    carry00 = (uint64_t)1U;
  else
    carry00 = (uint64_t)0U;
  uint64_t carry10;
  if (mask0 < a110)
    carry10 = (uint64_t)1U;
  else
    carry10 = (uint64_t)0U;
  uint64_t carry20;
  if (mask0 < a210)
    carry20 = (uint64_t)1U;
  else
    carry20 = (uint64_t)0U;
  uint64_t carry30;
  if (mask0 < a310)
    carry30 = (uint64_t)1U;
  else
    carry30 = (uint64_t)0U;
  uint64_t a0_updated0 = (a010 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated0 = (a110 << (uint32_t)1U) + carry00;
  uint64_t a2_updated0 = (a210 << (uint32_t)1U) + carry10;
  uint64_t a3_updated0 = (a310 << (uint32_t)1U) + carry20;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  multByTwo1 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry30,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated0,
          .snd = a1_updated0,
          .thd = a2_updated0,
          .f3 = a3_updated0
        }
      ));
  uint64_t a011 = multByTwo1.fst;
  uint64_t a111 = multByTwo1.snd;
  uint64_t a211 = multByTwo1.thd;
  uint64_t a311 = multByTwo1.f3;
  uint64_t mask1 = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry01;
  if (mask1 < a011)
    carry01 = (uint64_t)1U;
  else
    carry01 = (uint64_t)0U;
  uint64_t carry11;
  if (mask1 < a111)
    carry11 = (uint64_t)1U;
  else
    carry11 = (uint64_t)0U;
  uint64_t carry21;
  if (mask1 < a211)
    carry21 = (uint64_t)1U;
  else
    carry21 = (uint64_t)0U;
  uint64_t carry31;
  if (mask1 < a311)
    carry31 = (uint64_t)1U;
  else
    carry31 = (uint64_t)0U;
  uint64_t a0_updated1 = (a011 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated1 = (a111 << (uint32_t)1U) + carry01;
  uint64_t a2_updated1 = (a211 << (uint32_t)1U) + carry11;
  uint64_t a3_updated1 = (a311 << (uint32_t)1U) + carry21;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  multByFour1 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry31,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated1,
          .snd = a1_updated1,
          .thd = a2_updated1,
          .f3 = a3_updated1
        }
      ));
  K___uint64_t_uint64_t_uint64_t_uint64_t multByFour10 = multByFour1;
  uint64_t a01 = multByFour10.fst;
  uint64_t a11 = multByFour10.snd;
  uint64_t a21 = multByFour10.thd;
  uint64_t a31 = multByFour10.f3;
  uint64_t mask = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry0;
  if (mask < a01)
    carry0 = (uint64_t)1U;
  else
    carry0 = (uint64_t)0U;
  uint64_t carry1;
  if (mask < a11)
    carry1 = (uint64_t)1U;
  else
    carry1 = (uint64_t)0U;
  uint64_t carry2;
  if (mask < a21)
    carry2 = (uint64_t)1U;
  else
    carry2 = (uint64_t)0U;
  uint64_t carry3;
  if (mask < a31)
    carry3 = (uint64_t)1U;
  else
    carry3 = (uint64_t)0U;
  uint64_t a0_updated = (a01 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated = (a11 << (uint32_t)1U) + carry0;
  uint64_t a2_updated = (a21 << (uint32_t)1U) + carry1;
  uint64_t a3_updated = (a31 << (uint32_t)1U) + carry2;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry3,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated,
          .snd = a1_updated,
          .thd = a2_updated,
          .f3 = a3_updated
        }
      ));
  uint64_t m0 = scrut.fst;
  uint64_t m1 = scrut.snd;
  uint64_t m2 = scrut.thd;
  uint64_t m3 = scrut.f3;
  K___uint64_t_uint64_t_uint64_t_uint64_t scrut0 = { .fst = m0, .snd = m1, .thd = m2, .f3 = m3 };
  uint64_t r0 = scrut0.fst;
  uint64_t r1 = scrut0.snd;
  uint64_t r2 = scrut0.thd;
  uint64_t r3 = scrut0.f3;
  result[0U] = r0;
  result[1U] = r1;
  result[2U] = r2;
  result[3U] = r3;
}

static void multByMinusThree(uint64_t *a, uint64_t *result)
{
  uint64_t a0 = a[0U];
  uint64_t a1 = a[1U];
  uint64_t a2 = a[2U];
  uint64_t a3 = a[3U];
  uint64_t a010 = a0;
  uint64_t a110 = a1;
  uint64_t a210 = a2;
  uint64_t a310 = a3;
  uint64_t mask = (uint64_t)0x7fffffffffffffffU;
  uint64_t carry0;
  if (mask < a010)
    carry0 = (uint64_t)1U;
  else
    carry0 = (uint64_t)0U;
  uint64_t carry1;
  if (mask < a110)
    carry1 = (uint64_t)1U;
  else
    carry1 = (uint64_t)0U;
  uint64_t carry2;
  if (mask < a210)
    carry2 = (uint64_t)1U;
  else
    carry2 = (uint64_t)0U;
  uint64_t carry3;
  if (mask < a310)
    carry3 = (uint64_t)1U;
  else
    carry3 = (uint64_t)0U;
  uint64_t a0_updated = (a010 << (uint32_t)1U) + (uint64_t)0U;
  uint64_t a1_updated = (a110 << (uint32_t)1U) + carry0;
  uint64_t a2_updated = (a210 << (uint32_t)1U) + carry1;
  uint64_t a3_updated = (a310 << (uint32_t)1U) + carry2;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  multByTwo1 =
    Hacl_Spec_P256_Core_reduction_prime_2prime_with_carry(carry3,
      (
        (K___uint64_t_uint64_t_uint64_t_uint64_t){
          .fst = a0_updated,
          .snd = a1_updated,
          .thd = a2_updated,
          .f3 = a3_updated
        }
      ));
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut0 = { .fst = multByTwo1, .snd = { .fst = a0, .snd = a1, .thd = a2, .f3 = a3 } };
  uint64_t b3 = scrut0.snd.f3;
  uint64_t b2 = scrut0.snd.thd;
  uint64_t b1 = scrut0.snd.snd;
  uint64_t b0 = scrut0.snd.fst;
  uint64_t a31 = scrut0.fst.f3;
  uint64_t a21 = scrut0.fst.thd;
  uint64_t a11 = scrut0.fst.snd;
  uint64_t a01 = scrut0.fst.fst;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut1 =
    Hacl_Spec_Curve25519_Field64_Core_add4((
        (K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = a01, .snd = a11, .thd = a21, .f3 = a31 }
      ),
      ((K___uint64_t_uint64_t_uint64_t_uint64_t){ .fst = b0, .snd = b1, .thd = b2, .f3 = b3 }));
  uint64_t x7 = scrut1.snd.f3;
  uint64_t x5 = scrut1.snd.thd;
  uint64_t x3 = scrut1.snd.snd;
  uint64_t x1 = scrut1.snd.fst;
  uint64_t x8 = scrut1.fst;
  K___uint64_t_uint64_t
  scrut =
    Hacl_Spec_Curve25519_Field64_Core_subborrow(x1,
      (uint64_t)0xffffffffffffffffU,
      (uint64_t)0U);
  uint64_t o00 = scrut.fst;
  uint64_t c00 = scrut.snd;
  K___uint64_t_uint64_t
  scrut2 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x3, (uint64_t)0xffffffffU, c00);
  uint64_t o10 = scrut2.fst;
  uint64_t c10 = scrut2.snd;
  K___uint64_t_uint64_t
  scrut3 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x5, (uint64_t)0U, c10);
  uint64_t o20 = scrut3.fst;
  uint64_t c20 = scrut3.snd;
  K___uint64_t_uint64_t
  scrut4 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x7, (uint64_t)0xffffffff00000001U, c20);
  uint64_t o30 = scrut4.fst;
  uint64_t c30 = scrut4.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut5 = { .fst = c30, .snd = { .fst = o00, .snd = o10, .thd = o20, .f3 = o30 } };
  uint64_t x15 = scrut5.snd.f3;
  uint64_t x13 = scrut5.snd.thd;
  uint64_t x11 = scrut5.snd.snd;
  uint64_t x9 = scrut5.snd.fst;
  uint64_t x16 = scrut5.fst;
  K___uint64_t_uint64_t
  scrut6 = Hacl_Spec_Curve25519_Field64_Core_subborrow(x8, (uint64_t)0U, x16);
  uint64_t x18 = scrut6.snd;
  uint64_t b4 = (uint64_t)0U;
  uint64_t x20;
  if (x18 == b4)
    x20 = (uint64_t)0U;
  else
    x20 = (uint64_t)18446744073709551615U;
  uint64_t r00 = x1 & x20 | x9 & ~x20;
  uint64_t b5 = (uint64_t)0U;
  uint64_t x21;
  if (x18 == b5)
    x21 = (uint64_t)0U;
  else
    x21 = (uint64_t)18446744073709551615U;
  uint64_t r10 = x3 & x21 | x11 & ~x21;
  uint64_t b6 = (uint64_t)0U;
  uint64_t x22;
  if (x18 == b6)
    x22 = (uint64_t)0U;
  else
    x22 = (uint64_t)18446744073709551615U;
  uint64_t r20 = x5 & x22 | x13 & ~x22;
  uint64_t b7 = (uint64_t)0U;
  uint64_t x23;
  if (x18 == b7)
    x23 = (uint64_t)0U;
  else
    x23 = (uint64_t)18446744073709551615U;
  uint64_t r30 = x7 & x23 | x15 & ~x23;
  uint64_t r01 = r00;
  uint64_t r11 = r10;
  uint64_t r21 = r20;
  uint64_t r31 = r30;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  byThree = { .fst = r01, .snd = r11, .thd = r21, .f3 = r31 };
  K___uint64_t_uint64_t_uint64_t_uint64_t byThree0 = byThree;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  zero1 = { .fst = (uint64_t)0U, .snd = (uint64_t)0U, .thd = (uint64_t)0U, .f3 = (uint64_t)0U };
  K___K___uint64_t_uint64_t_uint64_t_uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut7 = { .fst = zero1, .snd = byThree0 };
  uint64_t f23 = scrut7.snd.f3;
  uint64_t f22 = scrut7.snd.thd;
  uint64_t f21 = scrut7.snd.snd;
  uint64_t f20 = scrut7.snd.fst;
  uint64_t f13 = scrut7.fst.f3;
  uint64_t f12 = scrut7.fst.thd;
  uint64_t f11 = scrut7.fst.snd;
  uint64_t f10 = scrut7.fst.fst;
  K___uint64_t_uint64_t
  scrut8 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f10, f20, (uint64_t)0U);
  uint64_t o0 = scrut8.fst;
  uint64_t c0 = scrut8.snd;
  K___uint64_t_uint64_t scrut9 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f11, f21, c0);
  uint64_t o1 = scrut9.fst;
  uint64_t c1 = scrut9.snd;
  K___uint64_t_uint64_t scrut10 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f12, f22, c1);
  uint64_t o2 = scrut10.fst;
  uint64_t c2 = scrut10.snd;
  K___uint64_t_uint64_t scrut11 = Hacl_Spec_Curve25519_Field64_Core_subborrow(f13, f23, c2);
  uint64_t o3 = scrut11.fst;
  uint64_t c3 = scrut11.snd;
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut12 = { .fst = c3, .snd = { .fst = o0, .snd = o1, .thd = o2, .f3 = o3 } };
  uint64_t c = scrut12.fst;
  K___uint64_t_uint64_t_uint64_t_uint64_t r = scrut12.snd;
  uint64_t b = (uint64_t)0U;
  uint64_t x2;
  if (c == b)
    x2 = (uint64_t)0U;
  else
    x2 = (uint64_t)18446744073709551615U;
  uint64_t x90 = (uint64_t)0xffffffffffffffffU & x2 | (uint64_t)0U & ~x2;
  uint64_t prime_temp_0 = (uint64_t)0xffffffffffffffffU & x90;
  uint64_t prime_temp_1 = (uint64_t)0xffffffffU & x90;
  uint64_t prime_temp_2 = (uint64_t)0U;
  uint64_t prime_temp_3 = (uint64_t)0xffffffff00000001U & x90;
  K___uint64_t_uint64_t_uint64_t_uint64_t
  prime_temp =
    { .fst = prime_temp_0, .snd = prime_temp_1, .thd = prime_temp_2, .f3 = prime_temp_3 };
  K___uint64_t_K___uint64_t_uint64_t_uint64_t_uint64_t
  scrut13 = Hacl_Spec_Curve25519_Field64_Core_add4(prime_temp, r);
  K___uint64_t_uint64_t_uint64_t_uint64_t minusThree = scrut13.snd;
  uint64_t r0 = minusThree.fst;
  uint64_t r1 = minusThree.snd;
  uint64_t r2 = minusThree.thd;
  uint64_t r3 = minusThree.f3;
  result[0U] = r0;
  result[1U] = r1;
  result[2U] = r2;
  result[3U] = r3;
}

static uint64_t isZero_uint64(uint64_t *f)
{
  uint64_t a0 = f[0U];
  uint64_t a1 = f[1U];
  uint64_t a2 = f[2U];
  uint64_t a3 = f[3U];
  uint64_t a01 = a0;
  uint64_t a11 = a1;
  uint64_t a21 = a2;
  uint64_t a31 = a3;
  uint64_t r0 = FStar_UInt64_eq_mask(a01, (uint64_t)0U);
  uint64_t r1 = FStar_UInt64_eq_mask(a11, (uint64_t)0U);
  uint64_t r2 = FStar_UInt64_eq_mask(a21, (uint64_t)0U);
  uint64_t r3 = FStar_UInt64_eq_mask(a31, (uint64_t)0U);
  uint64_t r01 = r0 & r1;
  uint64_t r23 = r2 & r3;
  return r01 & r23;
}

void point_double(uint64_t *p, uint64_t *result, uint64_t *tempBuffer)
{
  uint64_t *s1 = tempBuffer;
  uint64_t *m = tempBuffer + (uint32_t)4U;
  uint64_t *buffer_for_s_m = tempBuffer + (uint32_t)8U;
  uint64_t *buffer_for_x3 = tempBuffer + (uint32_t)32U;
  uint64_t *buffer_for_y3 = tempBuffer + (uint32_t)40U;
  uint64_t *pypz = tempBuffer + (uint32_t)56U;
  uint64_t *x3 = tempBuffer + (uint32_t)60U;
  uint64_t *y3 = tempBuffer + (uint32_t)64U;
  uint64_t *z3 = tempBuffer + (uint32_t)68U;
  uint64_t *p_y = p + (uint32_t)4U;
  uint64_t *p_z = p + (uint32_t)8U;
  uint64_t *px = p;
  uint64_t *py = p + (uint32_t)4U;
  uint64_t *pz = p + (uint32_t)8U;
  uint64_t *yy = buffer_for_s_m;
  uint64_t *xyy = buffer_for_s_m + (uint32_t)4U;
  uint64_t *zzzz = buffer_for_s_m + (uint32_t)8U;
  uint64_t *minThreeZzzz = buffer_for_s_m + (uint32_t)12U;
  uint64_t *xx = buffer_for_s_m + (uint32_t)16U;
  uint64_t *threeXx = buffer_for_s_m + (uint32_t)20U;
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(py, py, yy);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(px, yy, xyy);
  multByFour(xyy, s1);
  quatre(pz, zzzz);
  multByMinusThree(zzzz, minThreeZzzz);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(px, px, xx);
  multByThree(xx, threeXx);
  p256_add(minThreeZzzz, threeXx, m);
  uint64_t *twoS = buffer_for_x3;
  uint64_t *mm = buffer_for_x3 + (uint32_t)4U;
  multByTwo(s1, twoS);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(m, m, mm);
  p256_sub(mm, twoS, x3);
  uint64_t *yyyy = buffer_for_y3;
  uint64_t *eightYyyy = buffer_for_y3 + (uint32_t)4U;
  uint64_t *sx3 = buffer_for_y3 + (uint32_t)8U;
  uint64_t *msx3 = buffer_for_y3 + (uint32_t)12U;
  quatre(p_y, yyyy);
  multByEight(yyyy, eightYyyy);
  p256_sub(s1, x3, sx3);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(m, sx3, msx3);
  p256_sub(msx3, eightYyyy, y3);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(p_y, p_z, pypz);
  multByTwo(pypz, z3);
  memcpy(result, x3, (uint32_t)4U * sizeof x3[0U]);
  memcpy(result + (uint32_t)4U, y3, (uint32_t)4U * sizeof y3[0U]);
  memcpy(result + (uint32_t)8U, z3, (uint32_t)4U * sizeof z3[0U]);
}

static void
copy_point_conditional(
  uint64_t *x3_out,
  uint64_t *y3_out,
  uint64_t *z3_out,
  uint64_t *p,
  uint64_t *maskPoint
)
{
  uint64_t *z = maskPoint + (uint32_t)8U;
  uint64_t mask = isZero_uint64(z);
  uint64_t *p_x = p;
  uint64_t *p_y = p + (uint32_t)4U;
  uint64_t *p_z = p + (uint32_t)8U;
  uint64_t out_0 = x3_out[0U];
  uint64_t out_10 = x3_out[1U];
  uint64_t out_20 = x3_out[2U];
  uint64_t out_30 = x3_out[3U];
  uint64_t x_00 = p_x[0U];
  uint64_t x_10 = p_x[1U];
  uint64_t x_20 = p_x[2U];
  uint64_t x_30 = p_x[3U];
  uint64_t out_010 = out_0;
  uint64_t out_110 = out_10;
  uint64_t out_210 = out_20;
  uint64_t out_310 = out_30;
  uint64_t x_010 = x_00;
  uint64_t x_110 = x_10;
  uint64_t x_210 = x_20;
  uint64_t x_310 = x_30;
  uint64_t r_00 = out_010 ^ mask & (out_010 ^ x_010);
  uint64_t r_10 = out_110 ^ mask & (out_110 ^ x_110);
  uint64_t r_20 = out_210 ^ mask & (out_210 ^ x_210);
  uint64_t r_30 = out_310 ^ mask & (out_310 ^ x_310);
  uint64_t temp_00 = r_00;
  uint64_t temp_10 = r_10;
  uint64_t temp_20 = r_20;
  uint64_t temp_30 = r_30;
  x3_out[0U] = temp_00;
  x3_out[1U] = temp_10;
  x3_out[2U] = temp_20;
  x3_out[3U] = temp_30;
  uint64_t out_00 = y3_out[0U];
  uint64_t out_12 = y3_out[1U];
  uint64_t out_22 = y3_out[2U];
  uint64_t out_32 = y3_out[3U];
  uint64_t x_02 = p_y[0U];
  uint64_t x_12 = p_y[1U];
  uint64_t x_22 = p_y[2U];
  uint64_t x_32 = p_y[3U];
  uint64_t out_011 = out_00;
  uint64_t out_111 = out_12;
  uint64_t out_211 = out_22;
  uint64_t out_311 = out_32;
  uint64_t x_011 = x_02;
  uint64_t x_111 = x_12;
  uint64_t x_211 = x_22;
  uint64_t x_311 = x_32;
  uint64_t r_01 = out_011 ^ mask & (out_011 ^ x_011);
  uint64_t r_11 = out_111 ^ mask & (out_111 ^ x_111);
  uint64_t r_21 = out_211 ^ mask & (out_211 ^ x_211);
  uint64_t r_31 = out_311 ^ mask & (out_311 ^ x_311);
  uint64_t temp_01 = r_01;
  uint64_t temp_11 = r_11;
  uint64_t temp_21 = r_21;
  uint64_t temp_31 = r_31;
  y3_out[0U] = temp_01;
  y3_out[1U] = temp_11;
  y3_out[2U] = temp_21;
  y3_out[3U] = temp_31;
  uint64_t out_02 = z3_out[0U];
  uint64_t out_1 = z3_out[1U];
  uint64_t out_2 = z3_out[2U];
  uint64_t out_3 = z3_out[3U];
  uint64_t x_0 = p_z[0U];
  uint64_t x_1 = p_z[1U];
  uint64_t x_2 = p_z[2U];
  uint64_t x_3 = p_z[3U];
  uint64_t out_01 = out_02;
  uint64_t out_11 = out_1;
  uint64_t out_21 = out_2;
  uint64_t out_31 = out_3;
  uint64_t x_01 = x_0;
  uint64_t x_11 = x_1;
  uint64_t x_21 = x_2;
  uint64_t x_31 = x_3;
  uint64_t r_0 = out_01 ^ mask & (out_01 ^ x_01);
  uint64_t r_1 = out_11 ^ mask & (out_11 ^ x_11);
  uint64_t r_2 = out_21 ^ mask & (out_21 ^ x_21);
  uint64_t r_3 = out_31 ^ mask & (out_31 ^ x_31);
  uint64_t temp_0 = r_0;
  uint64_t temp_1 = r_1;
  uint64_t temp_2 = r_2;
  uint64_t temp_3 = r_3;
  z3_out[0U] = temp_0;
  z3_out[1U] = temp_1;
  z3_out[2U] = temp_2;
  z3_out[3U] = temp_3;
}

static uint64_t compare_felem(uint64_t *a, uint64_t *b)
{
  uint64_t a_0 = a[0U];
  uint64_t a_1 = a[1U];
  uint64_t a_2 = a[2U];
  uint64_t a_3 = a[3U];
  uint64_t b_0 = b[0U];
  uint64_t b_1 = b[1U];
  uint64_t b_2 = b[2U];
  uint64_t b_3 = b[3U];
  uint64_t a_01 = a_0;
  uint64_t a_11 = a_1;
  uint64_t a_21 = a_2;
  uint64_t a_31 = a_3;
  uint64_t b_01 = b_0;
  uint64_t b_11 = b_1;
  uint64_t b_21 = b_2;
  uint64_t b_31 = b_3;
  uint64_t r_0 = FStar_UInt64_eq_mask(a_01, b_01);
  uint64_t r_1 = FStar_UInt64_eq_mask(a_11, b_11);
  uint64_t r_2 = FStar_UInt64_eq_mask(a_21, b_21);
  uint64_t r_3 = FStar_UInt64_eq_mask(a_31, b_31);
  uint64_t r01 = r_0 & r_1;
  uint64_t r23 = r_2 & r_3;
  return r01 & r23;
}

void point_add(uint64_t *p, uint64_t *q, uint64_t *result, uint64_t *tempBuffer)
{
  uint64_t *z1 = p + (uint32_t)8U;
  uint64_t *z2 = q + (uint32_t)8U;
  uint64_t *tempBuffer16 = tempBuffer;
  uint64_t *u11 = tempBuffer + (uint32_t)16U;
  uint64_t *u2 = tempBuffer + (uint32_t)20U;
  uint64_t *s1 = tempBuffer + (uint32_t)24U;
  uint64_t *s2 = tempBuffer + (uint32_t)28U;
  uint64_t *h = tempBuffer + (uint32_t)32U;
  uint64_t *r = tempBuffer + (uint32_t)36U;
  uint64_t *uh = tempBuffer + (uint32_t)40U;
  uint64_t *hCube = tempBuffer + (uint32_t)44U;
  uint64_t *tempBuffer28 = tempBuffer + (uint32_t)60U;
  uint64_t *x1 = p;
  uint64_t *y1 = p + (uint32_t)4U;
  uint64_t *z11 = p + (uint32_t)8U;
  uint64_t *x2 = q;
  uint64_t *y2 = q + (uint32_t)4U;
  uint64_t *z210 = q + (uint32_t)8U;
  uint64_t *z2Square = tempBuffer16;
  uint64_t *z1Square = tempBuffer16 + (uint32_t)4U;
  uint64_t *z2Cube = tempBuffer16 + (uint32_t)8U;
  uint64_t *z1Cube = tempBuffer16 + (uint32_t)12U;
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z210, z210, z2Square);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z11, z11, z1Square);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z2Square,
    z210,
    z2Cube);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z1Square,
    z11,
    z1Cube);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(x1, z2Square, u11);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(x2, z1Square, u2);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(y1, z2Cube, s1);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(y2, z1Cube, s2);
  uint64_t one1 = compare_felem(u11, u2);
  uint64_t two = compare_felem(s1, s2);
  uint64_t z1notZero = isZero_uint64(z1);
  uint64_t z2notZero = isZero_uint64(z2);
  uint64_t pointsInf = ~z1notZero & ~z2notZero;
  uint64_t onetwo = one1 & two;
  uint64_t result1 = onetwo & pointsInf;
  bool flag = result1 == (uint64_t)0xffffffffffffffffU;
  if (flag)
    point_double(p, result, tempBuffer);
  else
  {
    uint64_t *temp = tempBuffer16;
    p256_sub(u2, u11, h);
    p256_sub(s2, s1, r);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(h, h, temp);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(u11, temp, uh);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(h, temp, hCube);
    uint64_t *z11 = p + (uint32_t)8U;
    uint64_t *z21 = q + (uint32_t)8U;
    uint64_t *tempBuffer161 = tempBuffer28;
    uint64_t *x3_out1 = tempBuffer28 + (uint32_t)16U;
    uint64_t *y3_out1 = tempBuffer28 + (uint32_t)20U;
    uint64_t *z3_out1 = tempBuffer28 + (uint32_t)24U;
    uint64_t *rSquare = tempBuffer161;
    uint64_t *r_h = tempBuffer161 + (uint32_t)4U;
    uint64_t *twouh = tempBuffer161 + (uint32_t)8U;
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(r, r, rSquare);
    p256_sub(rSquare, hCube, r_h);
    multByTwo(uh, twouh);
    p256_sub(r_h, twouh, x3_out1);
    uint64_t *s1hCube = tempBuffer161;
    uint64_t *u1hx3 = tempBuffer161 + (uint32_t)4U;
    uint64_t *ru1hx3 = tempBuffer161 + (uint32_t)8U;
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(s1, hCube, s1hCube);
    p256_sub(uh, x3_out1, u1hx3);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(r, u1hx3, ru1hx3);
    p256_sub(ru1hx3, s1hCube, y3_out1);
    uint64_t *z1z2 = tempBuffer161;
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z11, z21, z1z2);
    Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(h, z1z2, z3_out1);
    copy_point_conditional(x3_out1, y3_out1, z3_out1, q, p);
    copy_point_conditional(x3_out1, y3_out1, z3_out1, p, q);
    memcpy(result, x3_out1, (uint32_t)4U * sizeof x3_out1[0U]);
    memcpy(result + (uint32_t)4U, y3_out1, (uint32_t)4U * sizeof y3_out1[0U]);
    memcpy(result + (uint32_t)8U, z3_out1, (uint32_t)4U * sizeof z3_out1[0U]);
  }
}

void norm(uint64_t *p, uint64_t *resultPoint, uint64_t *tempBuffer)
{
  uint64_t *xf = p;
  uint64_t *yf = p + (uint32_t)4U;
  uint64_t *zf = p + (uint32_t)8U;
  uint64_t *resultX = resultPoint;
  uint64_t *resultY = resultPoint + (uint32_t)4U;
  uint64_t *resultZ = resultPoint + (uint32_t)8U;
  uint64_t *z2f = tempBuffer + (uint32_t)4U;
  uint64_t *z3f = tempBuffer + (uint32_t)8U;
  uint64_t *tempBuffer20 = tempBuffer + (uint32_t)12U;
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(zf, zf, z2f);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(z2f, zf, z3f);
  Hacl_Spec_P256_MontgomeryMultiplication_exponent(z2f, z2f, tempBuffer20);
  Hacl_Spec_P256_MontgomeryMultiplication_exponent(z3f, z3f, tempBuffer20);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(xf, z2f, z2f);
  Hacl_Spec_P256_MontgomeryMultiplication_montgomery_multiplication_buffer(yf, z3f, z3f);
  fromDomain(z2f, resultX);
  fromDomain(z3f, resultY);
  resultZ[0U] = (uint64_t)1U;
  resultZ[1U] = (uint64_t)0U;
  resultZ[2U] = (uint64_t)0U;
  resultZ[3U] = (uint64_t)0U;
}

void
montgomery_ladder(
  uint64_t *p,
  uint64_t *q,
  uint32_t scalarSize,
  uint8_t *scalar,
  uint64_t *tempBuffer
)
{
  for (uint32_t i = (uint32_t)0U; i < scalarSize; i = i + (uint32_t)1U)
  {
    uint32_t bit = scalarSize - i - (uint32_t)(krml_checked_int_t)1;
    uint64_t bit1 = (uint64_t)(scalar[bit / (uint32_t)8U] >> bit % (uint32_t)8U & (uint8_t)1U);
    Hacl_Spec_P256_MontgomeryMultiplication_cswap(bit1, p, q);
    point_add(q, p, q, tempBuffer);
    point_double(p, p, tempBuffer);
    Hacl_Spec_P256_MontgomeryMultiplication_cswap(bit1, p, q);
  }
}

void
scalarMultiplication(
  uint64_t *p,
  uint64_t *result,
  uint32_t scalarSize,
  uint8_t *scalar,
  uint64_t *tempBuffer
)
{
  uint32_t scalarSize1 = scalarSize * (uint32_t)(krml_checked_int_t)8;
  pointToDomain(p, result);
  uint64_t *q = tempBuffer;
  uint64_t *buff = tempBuffer + (uint32_t)12U;
  montgomery_ladder(q, result, scalarSize1, scalar, buff);
  norm(q, result, buff);
}

